{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:36.980207Z",
     "start_time": "2025-10-17T21:55:36.611759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import functools\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import logging\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict, List, Tuple, Any, Union, Callable, Iterable\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "from urllib.parse import urlparse\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n"
   ],
   "id": "4453e6517ce5bb64",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:37.068356Z",
     "start_time": "2025-10-17T21:55:37.039544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class GlobalConfig:\n",
    "    \"\"\"\n",
    "    Represents the global configuration for a data collection, processing, and API interactions system.\n",
    "\n",
    "    This class defines several constants and configurations necessary for interacting with various APIs,\n",
    "    structuring directories, and specifying default indicators for data extraction. It is useful for maintaining\n",
    "    a unified and centralized configuration setup, enabling seamless adjustments and reducing code redundancy.\n",
    "\n",
    "    Attributes:\n",
    "        COUNTRY_CODE (str): The ISO country code.\n",
    "        COUNTRY_NAME (str): Full name of the country.\n",
    "        START_YEAR (int): Start year for data collection.\n",
    "        END_YEAR (int): End year for data collection.\n",
    "        WORLD_BANK_API_URL (str): Base URL for the World Bank API.\n",
    "        INSTAD_API_URL (str): Base URL for Instad APIs.\n",
    "        OVERPASS_API_URL (str): Base URL for Overpass API.\n",
    "        FMI_API_URL (str): Base URL for the IMF API.\n",
    "        OMS_API_URL (str): Base URL for the WHO API.\n",
    "        UNDP_API_URL (str): URL for UNDP indicators data.\n",
    "        DEFAULT_PER_PAGE (int): Default number of results per page for API and data requests.\n",
    "        REQUEST_TIMEOUT (int): Timeout duration in seconds for API requests.\n",
    "        RETRY_COUNT (int): Number of retry attempts for failed API requests.\n",
    "        DELAY_BETWEEN_REQUESTS (float): Delay in seconds between consecutive API calls.\n",
    "        DIRECTORY_STRUCTURE (Dict[str, str]): Directory structure configuration dict with specified keys like\n",
    "            'data', 'raw', 'processed', etc.\n",
    "        DEFAULT_WB_INDICATORS (List[str]): Default World Bank economic and population indicators.\n",
    "        DEFAULT_IMF_INDICATORS (List[str]): Default IMF economic indicators.\n",
    "        DEFAULT_HEALTH_INDICATORS (List[str]): Default WHO health-related indicators.\n",
    "        OSM_ADMIN_LEVELS (Dict[str, str]): Administrative levels mapping for OSM data.\n",
    "        EXTERNAL_SCRAPING_URLS (Dict[str, str]): URLs for external scraping resources.\n",
    "        EXTERNAL_CSV_URLS (List[str]): External CSV file data source URLs.\n",
    "\n",
    "    Methods:\n",
    "        __post_init__(): Validates the initial configuration parameters to ensure consistency and correctness.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Raised if START_YEAR is greater than END_YEAR, if the years are outside the acceptable range\n",
    "            of 1900 to 2100, if RETRY_COUNT is less than 1, or REQUEST_TIMEOUT is less than 1.\n",
    "    \"\"\"\n",
    "    COUNTRY_CODE: str = \"BJ\"\n",
    "    COUNTRY_NAME: str = \"Bénin\"\n",
    "    START_YEAR: int = 2015\n",
    "    END_YEAR: int = 2024\n",
    "\n",
    "    WORLD_BANK_API_URL: str = \"https://api.worldbank.org/v2\"\n",
    "    INSTAD_API_URL: str = \"https://instad.bj\"\n",
    "    OVERPASS_API_URL: str = \"https://overpass-api.de/api/interpreter\"\n",
    "    FMI_API_URL: str = \"https://www.imf.org/external/datamapper/api/v1\"\n",
    "    OMS_API_URL: str = \"https://ghoapi.azureedge.net/api\"\n",
    "    UNDP_API_URL: str = (\n",
    "        \"https://hdr.undp.org/sites/default/files/2021-22_HDR/HDR21-22_Composite_indices_complete_time_series.csv\"\n",
    "    )\n",
    "\n",
    "    DEFAULT_PER_PAGE: int = 100\n",
    "    REQUEST_TIMEOUT: int = 30\n",
    "    RETRY_COUNT: int = 3\n",
    "    DELAY_BETWEEN_REQUESTS: float = 0.5\n",
    "\n",
    "    DIRECTORY_STRUCTURE: Dict[str, str] = field(\n",
    "        default_factory=lambda: {\n",
    "            \"data\": \"data_task_1\",\n",
    "            \"raw\": \"data_task_1/raw\",\n",
    "            \"processed\": \"data_task_1/processed\",\n",
    "            \"final_data\": \"data_task_1/final_data\",\n",
    "            \"logs\": \"logs\",\n",
    "            \"exports\": \"exports\",\n",
    "            \"docs\": \"docs\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    DEFAULT_WB_INDICATORS: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"SP.POP.TOTL\",\n",
    "            \"NY.GDP.MKTP.CD\",\n",
    "            \"NY.GDP.PCAP.CD\",\n",
    "            \"SE.PRM.NENR\",\n",
    "            \"SH.DYN.MORT\",\n",
    "            \"AG.LND.TOTL.K2\",\n",
    "            \"SL.TLF.TOTL.IN\",\n",
    "            \"SP.DYN.TFRT.IN\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    DEFAULT_IMF_INDICATORS: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"NGDP_R\",\n",
    "            \"NGDPD\",\n",
    "            \"PCPIPCH\",\n",
    "            \"LUR\",\n",
    "            \"GGX_NGDP\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    DEFAULT_HEALTH_INDICATORS: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"WHOSIS_000001\",\n",
    "            \"MDG_0000000001\",\n",
    "            \"MDG_0000000003\",\n",
    "            \"WHS4_544\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    OSM_ADMIN_LEVELS: Dict[str, str] = field(\n",
    "        default_factory=lambda: {\"pays\": \"2\", \"département\": \"4\", \"commune\": \"6\"}\n",
    "    )\n",
    "\n",
    "    EXTERNAL_SCRAPING_URLS: Dict[str, str] = field(\n",
    "        default_factory=lambda: {\n",
    "            \"rgph\": \"https://www.insae-bj.org/recensement-population.html\",\n",
    "            \"edc\": \"https://www.insae-bj.org/statistiques-economiques.html\",\n",
    "            \"emicov\": \"https://www.insae-bj.org/emicov.html\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    EXTERNAL_CSV_URLS: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"https://data.uis.unesco.org/medias/education/SDG4.csv\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.START_YEAR > self.END_YEAR:\n",
    "            raise ValueError(\n",
    "                f\"START_YEAR ({self.START_YEAR}) must be <= END_YEAR ({self.END_YEAR})\"\n",
    "            )\n",
    "        if not (1900 <= self.START_YEAR <= 2100 and 1900 <= self.END_YEAR <= 2100):\n",
    "            raise ValueError(\"Years must be between 1900 and 2100\")\n",
    "        if self.RETRY_COUNT < 1:\n",
    "            raise ValueError(\"RETRY_COUNT must be >= 1\")\n",
    "        if self.REQUEST_TIMEOUT < 1:\n",
    "            raise ValueError(\"REQUEST_TIMEOUT must be >= 1\")"
   ],
   "id": "1975124bd398c865",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:37.153662Z",
     "start_time": "2025-10-17T21:55:37.125827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CleaningReport:\n",
    "    \"\"\"\n",
    "    Represents a report detailing data cleaning and processing performed on a dataset.\n",
    "\n",
    "    This class is designed to store information about various cleaning operations\n",
    "    performed on dataset columns and rows, such as handling nulls, removing duplicates,\n",
    "    standardizing columns, converting data types, among others. It provides an organized\n",
    "    way to track the source of the dataset, the state of rows before and after cleaning,\n",
    "    and other specific actions taken during the cleaning process. Additionally, the class\n",
    "    offers a method for converting the cleaning report into a dictionary format.\n",
    "\n",
    "    Attributes:\n",
    "        source (str): The origin or source of the dataset.\n",
    "        initial_rows (int): The number of rows in the dataset before cleaning.\n",
    "        final_rows (int): The number of rows in the dataset after cleaning.\n",
    "        rows_removed (int): Total rows removed during the cleaning process. Defaults to 0.\n",
    "        duplicates_removed (int): Total duplicate rows removed. Defaults to 0.\n",
    "        nulls_handled (int): Total number of null values handled. Defaults to 0.\n",
    "        outliers_removed (int): Total outliers removed from the dataset. Defaults to 0.\n",
    "        columns_standardized (List[str]): List of columns that were standardized. Defaults to an empty list.\n",
    "        columns_dropped (List[str]): List of columns dropped during cleaning. Defaults to an empty list.\n",
    "        data_types_converted (Dict[str, str]): Dictionary of columns whose data types were converted,\n",
    "            mapping column names to their new data types. Defaults to an empty dictionary.\n",
    "        issues_detected (List[str]): List of issues or problems detected during cleaning. Defaults to an empty list.\n",
    "        cleaning_timestamp (datetime): The timestamp when cleaning was conducted. Defaults to the current time.\n",
    "\n",
    "    Methods:\n",
    "        to_dict:\n",
    "            Converts the cleaning report into a dictionary representation for easier\n",
    "            usage in logging, reporting, or further data analysis.\n",
    "\n",
    "            Returns:\n",
    "                Dict[str, Any]: A dictionary containing key information of the cleaning\n",
    "                report, including derived metrics like removal percentage and counts\n",
    "                of operations performed.\n",
    "    \"\"\"\n",
    "    source: str\n",
    "    initial_rows: int\n",
    "    final_rows: int\n",
    "    rows_removed: int = 0\n",
    "    duplicates_removed: int = 0\n",
    "    nulls_handled: int = 0\n",
    "    outliers_removed: int = 0\n",
    "    columns_standardized: List[str] = field(default_factory=list)\n",
    "    columns_dropped: List[str] = field(default_factory=list)\n",
    "    data_types_converted: Dict[str, str] = field(default_factory=dict)\n",
    "    issues_detected: List[str] = field(default_factory=list)\n",
    "    cleaning_timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"source\": self.source,\n",
    "            \"initial_rows\": self.initial_rows,\n",
    "            \"final_rows\": self.final_rows,\n",
    "            \"rows_removed\": self.rows_removed,\n",
    "            \"removal_percentage\": (\n",
    "                round((self.rows_removed / self.initial_rows * 100), 2)\n",
    "                if self.initial_rows > 0\n",
    "                else 0\n",
    "            ),\n",
    "            \"duplicates_removed\": self.duplicates_removed,\n",
    "            \"nulls_handled\": self.nulls_handled,\n",
    "            \"outliers_removed\": self.outliers_removed,\n",
    "            \"columns_standardized\": len(self.columns_standardized),\n",
    "            \"columns_dropped\": len(self.columns_dropped),\n",
    "            \"types_converted\": len(self.data_types_converted),\n",
    "            \"issues_count\": len(self.issues_detected),\n",
    "            \"timestamp\": self.cleaning_timestamp.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        }"
   ],
   "id": "fb4a628ba0b85238",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:37.289642Z",
     "start_time": "2025-10-17T21:55:37.269938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class PerformanceMetrics:\n",
    "    \"\"\"\n",
    "    Encapsulates performance metrics for tracking the execution of an operation.\n",
    "\n",
    "    This class provides attributes to measure and record the performance of an operation, such\n",
    "    as start and end times, duration, the number of items processed, and whether the operation\n",
    "    succeeded or failed. It includes utility methods for finalizing and converting recorded\n",
    "    metrics into a dictionary for further use or reporting.\n",
    "\n",
    "    Attributes:\n",
    "        operation_name (str): The name of the operation being tracked.\n",
    "        start_time (datetime): The starting time of the operation.\n",
    "        end_time (Optional[datetime]): The ending time of the operation. Defaults to None.\n",
    "        duration_seconds (float): The total duration of the operation in seconds. Defaults\n",
    "            to 0.0.\n",
    "        items_processed (int): The number of items processed during the operation. Defaults to 0.\n",
    "        success (bool): Indicates whether the operation was successful. Defaults to True.\n",
    "        error_message (Optional[str]): An optional message describing any error that occurred\n",
    "            during the operation. Defaults to None.\n",
    "        metadata (Dict[str, Any]): Additional information related to the operation, stored\n",
    "            as key-value pairs. Defaults to an empty dictionary.\n",
    "\n",
    "    Methods:\n",
    "        finalize(items: int = 0, success: bool = True, error: Optional[str] = None): Finalizes\n",
    "            the metrics by recording the end time, calculating the duration, and updating the\n",
    "            number of items, success flag, and error message.\n",
    "        to_dict() -> Dict[str, Any]: Converts the metrics to a dictionary format for reporting\n",
    "            or storage purposes.\n",
    "        __str__() -> str: Returns a string representation of the metrics for easy readability.\n",
    "    \"\"\"\n",
    "    operation_name: str\n",
    "    start_time: datetime\n",
    "    end_time: Optional[datetime] = None\n",
    "    duration_seconds: float = 0.0\n",
    "    items_processed: int = 0\n",
    "    success: bool = True\n",
    "    error_message: Optional[str] = None\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    def finalize(\n",
    "            self, items: int = 0, success: bool = True, error: Optional[str] = None\n",
    "    ):\n",
    "        self.end_time = datetime.now()\n",
    "        self.duration_seconds = (self.end_time - self.start_time).total_seconds()\n",
    "        self.items_processed = items\n",
    "        self.success = success\n",
    "        self.error_message = error\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"operation\": self.operation_name,\n",
    "            \"start\": self.start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"end\": (\n",
    "                self.end_time.strftime(\"%Y-%m-%d %H:%M:%S\") if self.end_time else None\n",
    "            ),\n",
    "            \"duration\": round(self.duration_seconds, 3),\n",
    "            \"items\": self.items_processed,\n",
    "            \"throughput\": (\n",
    "                round(self.items_processed / self.duration_seconds, 2)\n",
    "                if self.duration_seconds > 0\n",
    "                else 0\n",
    "            ),\n",
    "            \"success\": self.success,\n",
    "            \"error\": self.error_message,\n",
    "            **self.metadata,\n",
    "        }\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        status = \"✅\" if self.success else \"❌\"\n",
    "        duration_str = f\"{self.duration_seconds:.3f}s\"\n",
    "        if self.items_processed > 0:\n",
    "            throughput = (\n",
    "                self.items_processed / self.duration_seconds\n",
    "                if self.duration_seconds > 0\n",
    "                else 0\n",
    "            )\n",
    "            return f\"{status} {self.operation_name} | Durée: {duration_str} | Items: {self.items_processed} | Débit: {throughput:.2f} items/s\"\n",
    "        return f\"{status} {self.operation_name} | Durée: {duration_str}\""
   ],
   "id": "7f09aee7f053869f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:37.388790Z",
     "start_time": "2025-10-17T21:55:37.376987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_script() -> bool:\n",
    "    \"\"\"\n",
    "    Determines if the current executing script is being run as a standalone script.\n",
    "\n",
    "    This function checks if the module `__main__` (the entry point of the program) has\n",
    "    an attribute `__file__`, which indicates whether it is executed as a script or an\n",
    "    interactive session. This can be useful to distinguish between these two modes of\n",
    "    execution in Python.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the script is being executed as a standalone script, False otherwise.\n",
    "    \"\"\"\n",
    "    return hasattr(sys.modules[\"__main__\"], \"__file__\")"
   ],
   "id": "505a74c5877e93",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:37.485768Z",
     "start_time": "2025-10-17T21:55:37.464785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setup_environment(\n",
    "        log_dir: Optional[Path] = None, log_level: int = logging.INFO\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Sets up the environment by configuring logging, warnings, pandas options, and visualization settings.\n",
    "\n",
    "    This function handles the following:\n",
    "    - Configures the logging system to output messages to the console and optionally to a file.\n",
    "    - Suppresses deprecated, user, and future warnings.\n",
    "    - Adjusts pandas settings for data display, including maximum rows, column limits, and formatting.\n",
    "    - Customizes Seaborn and Matplotlib aesthetics for visualizations.\n",
    "\n",
    "    It is useful for initializing a consistent environment for data analysis or application workflows.\n",
    "\n",
    "    Parameters:\n",
    "    log_dir: Optional[Path]\n",
    "        Path to the directory where log files should be stored. If not provided, logging to\n",
    "        a file is disabled.\n",
    "    log_level: int\n",
    "        The logging level used to filter messages. Defaults to logging.INFO.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Raises:\n",
    "    None\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"bs4\")\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "    log_format = \"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\"\n",
    "    date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(logging.Formatter(log_format, date_format))\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=log_level,\n",
    "        format=log_format,\n",
    "        datefmt=date_format,\n",
    "        handlers=[console_handler],\n",
    "    )\n",
    "\n",
    "    if log_dir:\n",
    "        log_dir = Path(log_dir)\n",
    "        log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        file_handler = RotatingFileHandler(\n",
    "            log_dir / \"system.log\", maxBytes=2_000_000, backupCount=5, encoding=\"utf-8\"\n",
    "        )\n",
    "        file_handler.setFormatter(logging.Formatter(log_format, date_format))\n",
    "        logging.getLogger().addHandler(file_handler)\n",
    "\n",
    "    pd.set_option(\"display.max_rows\", 100)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "    pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.rcParams.update(\n",
    "        {\n",
    "            \"figure.figsize\": (12, 8),\n",
    "            \"axes.titlesize\": 14,\n",
    "            \"axes.labelsize\": 12,\n",
    "            \"xtick.labelsize\": 10,\n",
    "            \"ytick.labelsize\": 10,\n",
    "            \"legend.fontsize\": 10,\n",
    "        }\n",
    "    )\n",
    "    sns.set_palette(\"Set2\")"
   ],
   "id": "60e364b50a6a3fbe",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:37.606440Z",
     "start_time": "2025-10-17T21:55:37.572411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DirectoryManager:\n",
    "    \"\"\"\n",
    "    Manages directories and provides utility methods for structure initialization\n",
    "    and path retrieval.\n",
    "\n",
    "    The DirectoryManager class is designed to handle the creation and management\n",
    "    of directory structures. It enables initializing a directory structure based\n",
    "    on a given configuration, retrieving paths for specific directories, and listing\n",
    "    all managed directories. This is particularly useful in applications that require\n",
    "    consistency in directory organization.\n",
    "\n",
    "    Attributes:\n",
    "        base_dir (Path): The base directory where the structure will be created.\n",
    "            Defaults to the current script's directory or the current working\n",
    "            directory if not specified.\n",
    "        custom_structure (Optional[Dict[str, str]]): An optional custom directory\n",
    "            structure defined as a mapping of directory names to relative paths.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            base_dir: Optional[Path] = None,\n",
    "            custom_structure: Optional[Dict[str, str]] = None,\n",
    "    ):\n",
    "        self.base_dir = base_dir or (\n",
    "            Path(__file__).parent if is_script() else Path(\".\")\n",
    "        )\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self._directories: Dict[str, Path] = {}\n",
    "        self.custom_structure = custom_structure\n",
    "\n",
    "    def initialize_structure_directory(\n",
    "            self, structure: Optional[Dict[str, str]] = None\n",
    "    ) -> Dict[str, Path]:\n",
    "        structure_to_use = (\n",
    "                structure or self.custom_structure or GlobalConfig().DIRECTORY_STRUCTURE\n",
    "        )\n",
    "        for name, path in structure_to_use.items():\n",
    "            full_path = self.base_dir / path\n",
    "            full_path.mkdir(parents=True, exist_ok=True)\n",
    "            self._directories[name] = full_path\n",
    "        self.logger.info(f\"{len(self._directories)} dossiers créés avec succès.\")\n",
    "        return self._directories\n",
    "\n",
    "    def get_path(self, name: str) -> Optional[Path]:\n",
    "        path = self._directories.get(name)\n",
    "        if path is None:\n",
    "            self.logger.warning(f\"Le dossier '{name}' n'existe pas dans la structure.\")\n",
    "        return path\n",
    "\n",
    "    def list_directories(self) -> Dict[str, Path]:\n",
    "        return self._directories.copy()"
   ],
   "id": "bac3b166941ec5d6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:37.724030Z",
     "start_time": "2025-10-17T21:55:37.663172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AbstractCollector(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for data collection and saving operations.\n",
    "\n",
    "    This class provides a general framework for collecting data from various sources\n",
    "    and saving it in different formats. It includes methods to validate URLs,\n",
    "    handle HTTP requests with retries, and save data using multiple formats. The\n",
    "    class is designed to be extended by specific data collector implementations.\n",
    "\n",
    "    Attributes:\n",
    "        config (GlobalConfig): Configuration for the collector, including retry\n",
    "            counts, timeouts, and delays between requests.\n",
    "        logger (logging.Logger): Logger instance for recording events and errors.\n",
    "\n",
    "    Methods:\n",
    "        collect_data:\n",
    "            Abstract method that must be implemented by subclasses. Used to perform\n",
    "            the data collection task.\n",
    "\n",
    "        save_data:\n",
    "            Saves a DataFrame in a specified format to the provided file path.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, config: GlobalConfig):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.session = self._create_session()\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_session() -> requests.Session:\n",
    "        session = requests.Session()\n",
    "        session.headers.update(\n",
    "            {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Educational Research Bot/1.0)\",\n",
    "                \"Accept\": \"application/json, text/html, */*\",\n",
    "                \"Accept-Language\": \"fr,en;q=0.9\",\n",
    "            }\n",
    "        )\n",
    "        return session\n",
    "\n",
    "    def _validate_url(self, url: str) -> bool:\n",
    "        try:\n",
    "            result = urlparse(url)\n",
    "            return all([result.scheme, result.netloc])\n",
    "        except Exception as e:\n",
    "            self.logger.debug(f\"Invalid URL: {e}\")\n",
    "            return False\n",
    "\n",
    "    def _make_request_with_retry(\n",
    "            self, url: str, **kwargs\n",
    "    ) -> Tuple[Optional[requests.Response], bool]:\n",
    "        if not self._validate_url(url):\n",
    "            return None, False\n",
    "\n",
    "        method = kwargs.pop(\"method\", \"GET\")\n",
    "\n",
    "        for attempt in range(self.config.RETRY_COUNT):\n",
    "            try:\n",
    "                response = self.session.request(\n",
    "                    method=method,\n",
    "                    url=url,\n",
    "                    timeout=self.config.REQUEST_TIMEOUT,\n",
    "                    **kwargs,\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                if self.config.DELAY_BETWEEN_REQUESTS > 0:\n",
    "                    time.sleep(self.config.DELAY_BETWEEN_REQUESTS)\n",
    "                return response, True\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                status_code = e.response.status_code if e.response else \"N/A\"\n",
    "                self.logger.warning(\n",
    "                    f\"🔄 Attempt {attempt + 1}/{self.config.RETRY_COUNT} - HTTP {status_code} on {url}\"\n",
    "                )\n",
    "            except requests.exceptions.Timeout:\n",
    "                self.logger.warning(\n",
    "                    f\"🔄 Attempt {attempt + 1}/{self.config.RETRY_COUNT} - Timeout on {url}\"\n",
    "                )\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                self.logger.warning(\n",
    "                    f\"🔄 Attempt {attempt + 1}/{self.config.RETRY_COUNT} - Connection error on {url}\"\n",
    "                )\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                self.logger.warning(\n",
    "                    f\"🔄 Attempt {attempt + 1}/{self.config.RETRY_COUNT} - Error on {url}: {e}\"\n",
    "                )\n",
    "\n",
    "            if attempt < self.config.RETRY_COUNT - 1:\n",
    "                sleep_time = 2 ** attempt\n",
    "                self.logger.debug(f\"Waiting {sleep_time}s before retry...\")\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "        self.logger.error(f\"❌ Failed after {self.config.RETRY_COUNT} attempts: {url}\")\n",
    "        return None, False\n",
    "\n",
    "    @abstractmethod\n",
    "    def collect_data(self) -> Union[pd.DataFrame, Dict[str, pd.DataFrame]]:\n",
    "        pass\n",
    "\n",
    "    def save_data(\n",
    "            self,\n",
    "            data: pd.DataFrame,\n",
    "            file_path: Path,\n",
    "            format_type: str = \"csv\",\n",
    "            add_metadata: bool = True,\n",
    "    ) -> Tuple[bool, Optional[Path]]:\n",
    "        if not isinstance(file_path, Path):\n",
    "            raise TypeError(\"file_path must be a pathlib.Path object\")\n",
    "        if data.empty:\n",
    "            self.logger.warning(\"Empty DataFrame, no data to save.\")\n",
    "            return False, None\n",
    "\n",
    "        try:\n",
    "            meta_data = data.copy()\n",
    "            if add_metadata:\n",
    "                meta_data[\"collection_timestamp\"] = datetime.now()\n",
    "                meta_data[\"collector\"] = self.__class__.__name__\n",
    "\n",
    "            format_type = format_type.lower()\n",
    "            if format_type == \"csv\":\n",
    "                meta_data.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
    "            elif format_type == \"excel\":\n",
    "                meta_data.to_excel(file_path, index=False, engine=\"openpyxl\")\n",
    "            elif format_type == \"json\":\n",
    "                meta_data.to_json(\n",
    "                    file_path,\n",
    "                    orient=\"records\",\n",
    "                    force_ascii=False,\n",
    "                    indent=2,\n",
    "                    date_format=\"iso\",\n",
    "                )\n",
    "            elif format_type == \"parquet\":\n",
    "                meta_data.to_parquet(file_path, index=False)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported format: {format_type}\")\n",
    "\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            self.logger.info(\n",
    "                f\"✅ Saved: {file_path.name} ({len(data)} rows, {size_mb:.2f} MB)\"\n",
    "            )\n",
    "            return True, file_path\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Save error {file_path}: {e}\")\n",
    "            return False, None"
   ],
   "id": "ecb7f7600f7a7f28",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:37.771781Z",
     "start_time": "2025-10-17T21:55:37.756647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PerformanceTracker:\n",
    "    \"\"\"\n",
    "    Tracks and summarizes performance metrics for various operations.\n",
    "\n",
    "    This class is designed to collect and manage performance metrics, which\n",
    "    can be used to analyze the efficiency and effectiveness of various operations.\n",
    "    It provides functionalities to add new metrics, summarize them, and print\n",
    "    a consolidated report. Useful for logging and debugging purposes in scenarios\n",
    "    where monitoring performance is critical.\n",
    "\n",
    "    Attributes:\n",
    "        metrics: List of performance metrics collected, holding objects of type\n",
    "            PerformanceMetrics.\n",
    "        logger: Logger instance specifically for the class, used to log internal\n",
    "            events and debug information.\n",
    "\n",
    "    Methods:\n",
    "        add_metric(metric: PerformanceMetrics):\n",
    "            Adds a new performance metric to the tracker.\n",
    "\n",
    "        get_summary() -> Dict[str, Any]:\n",
    "            Returns a summary of collected performance data.\n",
    "\n",
    "        print_summary():\n",
    "            Prints the summarized performance data in a formatted view.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.metrics: List[PerformanceMetrics] = []\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "    def add_metric(self, metric: PerformanceMetrics) -> None:\n",
    "        self.metrics.append(metric)\n",
    "        self.logger.debug(f\"{metric.operation_name}: {metric}\")\n",
    "\n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        if not self.metrics:\n",
    "            return {\"total_operations\": 0}\n",
    "        total_duration = sum(m.duration_seconds for m in self.metrics)\n",
    "        successful = sum(1 for m in self.metrics if m.success)\n",
    "        return {\n",
    "            \"total_operations\": len(self.metrics),\n",
    "            \"successful\": successful,\n",
    "            \"failed\": len(self.metrics) - successful,\n",
    "            \"total_duration\": round(total_duration, 3),\n",
    "            \"avg_duration\": round(total_duration / len(self.metrics), 3),\n",
    "            \"total_items\": sum(m.items_processed for m in self.metrics),\n",
    "        }\n",
    "\n",
    "    def print_summary(self):\n",
    "        summary = self.get_summary()\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"RÉSUMÉ DES PERFORMANCES\")\n",
    "        print(\"=\" * 70)\n",
    "        for key, value in summary.items():\n",
    "            print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "        print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "\n",
    "_global_tracker = PerformanceTracker()"
   ],
   "id": "377f63e4c1d8a2bc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:37.886386Z",
     "start_time": "2025-10-17T21:55:37.841520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def timer(\n",
    "        operation_name: Optional[str] = None,\n",
    "        log_result: bool = True,\n",
    "        track_metrics: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Decorator to measure and log the execution time of a function.\n",
    "\n",
    "    This decorator allows you to track the performance of a function by measuring its\n",
    "    execution time and, optionally, logging the result and tracking performance metrics.\n",
    "    It uses the PerformanceMetrics helper to record the operation name, duration, success\n",
    "    status, and any error that occurred.\n",
    "\n",
    "    Parameters:\n",
    "    operation_name: Optional[str]\n",
    "        The name of the operation to be tracked. If not provided, the module and function\n",
    "        name of the decorated function will be used.\n",
    "    log_result: bool\n",
    "        Determines whether the result of the execution should be logged. Defaults to True.\n",
    "    track_metrics: bool\n",
    "        Determines whether the performance metrics should be tracked using a global tracker.\n",
    "        Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    Callable\n",
    "        A decorated function that measures and logs its execution time.\n",
    "\n",
    "    Raises:\n",
    "    Exception\n",
    "        Propagates any exception raised by the decorated function.\n",
    "    \"\"\"\n",
    "    def decorator(func: Callable) -> Callable:\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs) -> Any:\n",
    "            op_name = (\n",
    "                    operation_name\n",
    "                    or f\"{getattr(func, '__module__', '<unknown>')}.{func.__name__}\"\n",
    "            )\n",
    "            metric = PerformanceMetrics(\n",
    "                operation_name=op_name, start_time=datetime.now()\n",
    "            )\n",
    "            logger = logging.getLogger(getattr(func, \"__module__\", \"<unknown>\"))\n",
    "\n",
    "            if log_result:\n",
    "                logger.info(f\"⏱️  Start: {op_name}\")\n",
    "\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                metric.finalize(success=True)\n",
    "                if log_result:\n",
    "                    logger.info(f\"✅ Done: {op_name} in {metric.duration_seconds:.3f}s\")\n",
    "                if track_metrics:\n",
    "                    _global_tracker.add_metric(metric)\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                metric.finalize(success=False, error=str(e))\n",
    "                if log_result:\n",
    "                    logger.error(\n",
    "                        f\"❌ Failed: {op_name} after {metric.duration_seconds:.3f}s - {e}\"\n",
    "                    )\n",
    "                if track_metrics:\n",
    "                    _global_tracker.add_metric(metric)\n",
    "                raise\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator"
   ],
   "id": "4a6cff33e3a8ba63",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:37.930435Z",
     "start_time": "2025-10-17T21:55:37.921716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@contextmanager\n",
    "def track_progress(\n",
    "        iterable: Iterable,\n",
    "        desc: str = \"Processing\",\n",
    "        total: Optional[int] = None,\n",
    "        unit: str = \"item\",\n",
    "        leave: bool = True,\n",
    "        **tqdm_kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Context manager for tracking progress of iterations using tqdm.\n",
    "\n",
    "    This context manager wraps an iterable with tqdm to display a progress bar,\n",
    "    providing real-time feedback on the progress of iteration steps. The optional\n",
    "    parameters allow customization of the progress bar's display.\n",
    "\n",
    "    Parameters:\n",
    "        iterable (Iterable): The iterable whose progress is being tracked.\n",
    "        desc (str): Description text displayed on the progress bar. Defaults\n",
    "                    to \"Processing\".\n",
    "        total (Optional[int]): The total number of items to iterate over.\n",
    "                               If None, the iterable length is used if\n",
    "                               available. Defaults to None.\n",
    "        unit (str): Unit description for each iteration step. Defaults to \"item\".\n",
    "        leave (bool): Whether to keep the progress bar after completion.\n",
    "                      Defaults to True.\n",
    "        **tqdm_kwargs: Additional keyword arguments to customize tqdm behavior.\n",
    "\n",
    "    Yields:\n",
    "        tqdm.std.tqdm: A tqdm progress bar object wrapping the given iterable.\n",
    "    \"\"\"\n",
    "    pbar = tqdm(\n",
    "        iterable=iterable,\n",
    "        desc=desc,\n",
    "        total=total,\n",
    "        unit=unit,\n",
    "        leave=leave,\n",
    "        ncols=100,\n",
    "        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\",\n",
    "        **tqdm_kwargs,\n",
    "    )\n",
    "    try:\n",
    "        yield pbar\n",
    "    finally:\n",
    "        pbar.close()"
   ],
   "id": "1ac007c6df8ac9b1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:38.014188Z",
     "start_time": "2025-10-17T21:55:37.989802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class WorldBankCollector(AbstractCollector):\n",
    "    \"\"\"\n",
    "    Handles World Bank data collection.\n",
    "\n",
    "    This class is responsible for collecting and processing data from the World Bank API.\n",
    "    It fetches indicator data for specified countries and years, processes the raw data,\n",
    "    and aggregates the results into a structured DataFrame. The class structures its\n",
    "    workflow for retry mechanisms, error logging, and performance metrics tracking.\n",
    "    \"\"\"\n",
    "    @timer(operation_name=\"WorldBank.fetch_indicator\", track_metrics=True)\n",
    "    def _fetch_indicator_data(\n",
    "            self,\n",
    "            indicator: str,\n",
    "            start_year: Optional[int] = None,\n",
    "            end_year: Optional[int] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        url = f\"{self.config.WORLD_BANK_API_URL}/country/{self.config.COUNTRY_CODE}/indicator/{indicator}\"\n",
    "        params = {\n",
    "            \"date\": f\"{start_year or self.config.START_YEAR}:{end_year or self.config.END_YEAR}\",\n",
    "            \"format\": \"json\",\n",
    "            \"per_page\": self.config.DEFAULT_PER_PAGE,\n",
    "        }\n",
    "        response, success = self._make_request_with_retry(url, params=params)\n",
    "        if not success or response is None:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            data = response.json()\n",
    "            entries = data[1] if isinstance(data, list) and len(data) > 1 else []\n",
    "            records = [\n",
    "                {\n",
    "                    \"indicator_code\": entry[\"indicator\"][\"id\"],\n",
    "                    \"indicator_name\": entry[\"indicator\"][\"value\"],\n",
    "                    \"country_code\": entry[\"country\"][\"id\"],\n",
    "                    \"country_name\": entry[\"country\"][\"value\"],\n",
    "                    \"year\": pd.to_numeric(entry[\"date\"], errors=\"coerce\"),\n",
    "                    \"value\": pd.to_numeric(entry[\"value\"], errors=\"coerce\"),\n",
    "                    \"source\": \"World Bank API\",\n",
    "                }\n",
    "                for entry in entries\n",
    "            ]\n",
    "            return pd.DataFrame(records)\n",
    "        except (ValueError, KeyError, IndexError) as e:\n",
    "            self.logger.error(f\"❌ Parse error {indicator}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    @timer(operation_name=\"WorldBank.collect_all\", track_metrics=True)\n",
    "    def collect_data(self, indicators: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        indicators = indicators or self.config.DEFAULT_WB_INDICATORS\n",
    "        self.logger.info(\n",
    "            f\"🌍 Start World Bank collection ({len(indicators)} indicators)\"\n",
    "        )\n",
    "        all_data = []\n",
    "        with track_progress(indicators, desc=\"World Bank\", unit=\"indicator\") as pbar:\n",
    "            for indicator in pbar:\n",
    "                pbar.set_postfix_str(f\"Indicator: {indicator}\")\n",
    "                df = self._fetch_indicator_data(indicator)\n",
    "                if not df.empty:\n",
    "                    all_data.append(df)\n",
    "                    self.logger.info(f\"✅ {len(df)} records collected\")\n",
    "                time.sleep(self.config.DELAY_BETWEEN_REQUESTS)\n",
    "\n",
    "        result = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "        metric = PerformanceMetrics(\n",
    "            operation_name=\"WorldBank.collect_summary\",\n",
    "            start_time=datetime.now(),\n",
    "            items_processed=len(result),\n",
    "        )\n",
    "        metric.finalize(items=len(result))\n",
    "        _global_tracker.add_metric(metric)\n",
    "        self.logger.info(f\"✅ World Bank done: {len(result)} records\")\n",
    "        return result"
   ],
   "id": "5812894b51037eb6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:38.124662Z",
     "start_time": "2025-10-17T21:55:38.078497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class WebScrapingCollector(AbstractCollector):\n",
    "    \"\"\"\n",
    "    WebScrapingCollector handles the process of scraping tabular data from web pages and consolidating\n",
    "    it into a structured format.\n",
    "\n",
    "    This class is designed to perform web scraping for extracting HTML tables from specific URLs and transform them\n",
    "    into a Pandas DataFrame for further processing. It provides functionality to collect data from multiple sources\n",
    "    simultaneously and ensures data integrity by cleaning up the tables before they are consolidated into the final\n",
    "    output. The scraping tasks are tracked with metrics, and progress is logged effectively.\n",
    "\n",
    "    Attributes:\n",
    "        logger: Logging utility used for tracking the scraping process.\n",
    "    \"\"\"\n",
    "    @timer(operation_name=\"WebScraping.scrape_tables\", track_metrics=True)\n",
    "    def _scrape_html_tables(\n",
    "        self, url: str, source_name: str, max_tables: int = 10\n",
    "    ) -> pd.DataFrame:\n",
    "        response, success = self._make_request_with_retry(url)\n",
    "        if not success or response is None:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            tables = soup.find_all(\"table\")\n",
    "            self.logger.info(f\"📋 {len(tables)} tables found on {url}\")\n",
    "            \n",
    "            scraped_data = []\n",
    "            for i, table in enumerate(tables[:max_tables]):\n",
    "                try:\n",
    "                    df = pd.read_html(str(table), header=0)[0]\n",
    "                    \n",
    "                    if df.empty or len(df.columns) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    df = df.dropna(how='all', axis=0)\n",
    "                    df = df.dropna(how='all', axis=1)\n",
    "                    \n",
    "                    if df.empty:\n",
    "                        continue\n",
    "                    \n",
    "                    df.columns = [str(col).strip() for col in df.columns]\n",
    "                    \n",
    "                    df['source_url'] = url\n",
    "                    df['source_name'] = source_name\n",
    "                    df['table_index'] = i\n",
    "                    df['extraction_date'] = datetime.now()\n",
    "                    \n",
    "                    scraped_data.append(df)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.logger.debug(f\"Skipping table {i}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if not scraped_data:\n",
    "                self.logger.warning(f\"No valid tables extracted from {url}\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            return pd.concat(scraped_data, ignore_index=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Scraping error {url}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    @timer(operation_name=\"WebScraping.collect_all\", track_metrics=True)\n",
    "    def collect_data(self, max_tables: int = 10) -> pd.DataFrame:\n",
    "        self.logger.info(\"🕷️ Start web scraping\")\n",
    "        urls = {\n",
    "            \"instad_trimestres\": \"https://instad.bj/publications/publications-trimestrielles\",\n",
    "            \"instad_mensuelles\": \"https://instad.bj/publications/publications-mensuelles\",\n",
    "        }\n",
    "        all_data = []\n",
    "        with track_progress(\n",
    "            urls.items(), desc=\"Web Scraping\", total=len(urls), unit=\"site\"\n",
    "        ) as pbar:\n",
    "            for source_name, url in pbar:\n",
    "                pbar.set_postfix_str(f\"Source: {source_name}\")\n",
    "                df = self._scrape_html_tables(url, source_name, max_tables)\n",
    "                if not df.empty:\n",
    "                    all_data.append(df)\n",
    "        \n",
    "        result = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "        self.logger.info(f\"✅ Scraping done: {len(result)} records\")\n",
    "        return result"
   ],
   "id": "9bd23b36419ef414",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:38.211441Z",
     "start_time": "2025-10-17T21:55:38.164320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GeographicCollector(AbstractCollector):\n",
    "    \"\"\"\n",
    "    Collects and processes geographic data using Overpass API.\n",
    "\n",
    "    This class is responsible for collecting geographic information such as cities\n",
    "    and administrative boundaries. It connects to the Overpass API, runs specific\n",
    "    queries, processes the responses, and returns the results in a structured\n",
    "    format. The primary goal is to gather location-based data relevant to a given\n",
    "    region or country for further analysis.\n",
    "\n",
    "    Methods:\n",
    "        collect_data: Initiates the collection process for cities and administrative\n",
    "        boundaries and organizes the data into structured outputs.\n",
    "\n",
    "    \"\"\"\n",
    "    @timer(operation_name=\"Geographic.execute_query\", track_metrics=True)\n",
    "    def _execute_overpass_query(self, query: str, data_type: str) -> pd.DataFrame:\n",
    "        response, success = self._make_request_with_retry(\n",
    "            self.config.OVERPASS_API_URL, data={\"data\": query}, method=\"POST\"\n",
    "        )\n",
    "        if not success or response is None:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            data = response.json()\n",
    "            elements = data.get(\"elements\", [])\n",
    "            records = []\n",
    "            for element in elements:\n",
    "                if \"tags\" not in element:\n",
    "                    continue\n",
    "                record = {\n",
    "                    \"name\": element[\"tags\"].get(\"name\"),\n",
    "                    \"osm_id\": element.get(\"id\"),\n",
    "                    \"latitude\": element.get(\"lat\")\n",
    "                                or element.get(\"center\", {}).get(\"lat\"),\n",
    "                    \"longitude\": element.get(\"lon\")\n",
    "                                 or element.get(\"center\", {}).get(\"lon\"),\n",
    "                    \"data_type\": data_type,\n",
    "                    \"source\": \"OpenStreetMap\",\n",
    "                }\n",
    "                if data_type == \"cities\":\n",
    "                    record.update(\n",
    "                        {\n",
    "                            \"place_type\": element[\"tags\"].get(\"place\"),\n",
    "                            \"population\": pd.to_numeric(\n",
    "                                element[\"tags\"].get(\"population\"), errors=\"coerce\"\n",
    "                            ),\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    record.update(\n",
    "                        {\n",
    "                            \"admin_level\": element[\"tags\"].get(\"admin_level\"),\n",
    "                            \"wikidata\": element[\"tags\"].get(\"wikidata\"),\n",
    "                        }\n",
    "                    )\n",
    "                records.append(record)\n",
    "            self.logger.info(f\"📍 {len(records)} {data_type} elements collected\")\n",
    "            return pd.DataFrame(records)\n",
    "        except (ValueError, KeyError) as e:\n",
    "            self.logger.error(f\"❌ Parse error Overpass {data_type}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    @timer(operation_name=\"Geographic.collect_all\", track_metrics=True)\n",
    "    def collect_data(self) -> Dict[str, pd.DataFrame]:\n",
    "        self.logger.info(\"🗺️ Start geographic collection\")\n",
    "        results = {}\n",
    "        cities_query = f\"\"\"\n",
    "        [out:json][timeout:60];\n",
    "        area[\"ISO3166-1\"=\"{self.config.COUNTRY_CODE}\"];\n",
    "        (node(area)[\"place\"~\"city|town|village\"]; way(area)[\"place\"~\"city|town|village\"];);\n",
    "        out center tags;\n",
    "        \"\"\"\n",
    "        cities_df = self._execute_overpass_query(cities_query, \"cities\")\n",
    "        if not cities_df.empty:\n",
    "            results[\"cities\"] = cities_df\n",
    "\n",
    "        admin_levels = list(self.config.OSM_ADMIN_LEVELS.items())\n",
    "        with track_progress(\n",
    "                admin_levels, desc=\"Admin boundaries\", unit=\"level\"\n",
    "        ) as pbar:\n",
    "            for level_name, level_code in pbar:\n",
    "                pbar.set_postfix_str(f\"Level: {level_name}\")\n",
    "                admin_query = f\"\"\"\n",
    "                [out:json][timeout:60];\n",
    "                relation[\"boundary\"=\"administrative\"][\"admin_level\"=\"{level_code}\"][\"name\"~\"{self.config.COUNTRY_NAME}|Benin\"];\n",
    "                out center tags;\n",
    "                \"\"\"\n",
    "                admin_df = self._execute_overpass_query(\n",
    "                    admin_query, f\"admin_{level_name}\"\n",
    "                )\n",
    "                if not admin_df.empty:\n",
    "                    results[f\"admin_{level_name}\"] = admin_df\n",
    "\n",
    "        total = sum(len(df) for df in results.values())\n",
    "        self.logger.info(f\"✅ Geographic done: {total} records\")\n",
    "        return results"
   ],
   "id": "243a121c6ed8c98",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:38.284841Z",
     "start_time": "2025-10-17T21:55:38.256822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ExternalCollector(AbstractCollector):\n",
    "    \"\"\"\n",
    "    Defines the ExternalCollector class, which is responsible for collecting and processing external data\n",
    "    sources. This class fetches content from specified URLs, processes it into structured data formats,\n",
    "    and normalizes it for downstream analysis. It provides functionality to handle multiple URLs and\n",
    "    combines the data into a unified result.\n",
    "\n",
    "    Attributes:\n",
    "        config: Configuration object containing external data source URLs.\n",
    "        logger: Logger instance to record activities and errors during data collection.\n",
    "\n",
    "    Parameters:\n",
    "        AbstractCollector: Base class, which ExternalCollector extends functionality from.\n",
    "    \"\"\"\n",
    "    @timer(operation_name=\"External.download_file\", track_metrics=True)\n",
    "    def _download_data(self, url: str) -> pd.DataFrame:\n",
    "        response, success = self._make_request_with_retry(url)\n",
    "        if not success or response is None:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            from io import BytesIO\n",
    "\n",
    "            content = response.content\n",
    "            try:\n",
    "                df = pd.read_csv(BytesIO(content))\n",
    "                df[\"source\"] = url\n",
    "                return df\n",
    "            except pd.errors.EmptyDataError:\n",
    "                self.logger.warning(f\"⚠️ Empty file: {url}\")\n",
    "                return pd.DataFrame()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                import json\n",
    "\n",
    "                json_data = json.loads(content)\n",
    "                df = pd.json_normalize(json_data)\n",
    "                df[\"source\"] = url\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"❌ Unsupported format for {url}: {e}\")\n",
    "                return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Download error {url}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    @timer(operation_name=\"External.collect_all\", track_metrics=True)\n",
    "    def collect_data(self, urls: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        urls = urls or self.config.EXTERNAL_CSV_URLS\n",
    "        self.logger.info(f\"🌐 External collection ({len(urls)} sources)\")\n",
    "        all_data = []\n",
    "        with track_progress(\n",
    "                enumerate(urls, 1), desc=\"External sources\", total=len(urls), unit=\"source\"\n",
    "        ) as pbar:\n",
    "            for i, url in pbar:\n",
    "                pbar.set_postfix_str(f\"URL {i}/{len(urls)}\")\n",
    "                df = self._download_data(url)\n",
    "                if not df.empty:\n",
    "                    all_data.append(df)\n",
    "                    self.logger.info(f\"✅ {len(df)} records\")\n",
    "        result = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "        self.logger.info(f\"✅ External done: {len(result)} records\")\n",
    "        return result"
   ],
   "id": "1e245b1be29df47f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:38.379856Z",
     "start_time": "2025-10-17T21:55:38.344133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IMFCollector(AbstractCollector):\n",
    "    \"\"\"\n",
    "    Collector class for fetching and processing IMF indicator data.\n",
    "\n",
    "    This class is responsible for collecting data from the IMF API based on\n",
    "    specified indicators, handling API responses and errors, and transforming\n",
    "    the data into a pandas DataFrame for further use. It supports retrying\n",
    "    failed requests, tracking performance metrics, and logging the progress of\n",
    "    the data collection process.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    _fetch_indicator_data(indicator: str) -> pd.DataFrame\n",
    "        Retrieves a single indicator's data from the IMF API and processes\n",
    "        it into a pandas DataFrame.\n",
    "\n",
    "    collect_data(indicators: Optional[List[str]] = None) -> pd.DataFrame\n",
    "        Collects data for multiple indicators from the IMF API and aggregates\n",
    "        them into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    @timer(operation_name=\"IMF.fetch_indicator\", track_metrics=True)\n",
    "    def _fetch_indicator_data(self, indicator: str) -> pd.DataFrame:\n",
    "        url = f\"{self.config.FMI_API_URL}/{indicator}\"\n",
    "        response, success = self._make_request_with_retry(url)\n",
    "        if not success or response is None:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            data = response.json()\n",
    "            records = []\n",
    "            if isinstance(data, dict) and \"values\" in data:\n",
    "                country_data = (\n",
    "                    data[\"values\"].get(indicator, {}).get(self.config.COUNTRY_CODE, {})\n",
    "                )\n",
    "                for year, value in country_data.items():\n",
    "                    records.append(\n",
    "                        {\n",
    "                            \"indicator_code\": indicator,\n",
    "                            \"country_code\": self.config.COUNTRY_CODE,\n",
    "                            \"year\": pd.to_numeric(year, errors=\"coerce\"),\n",
    "                            \"value\": pd.to_numeric(value, errors=\"coerce\"),\n",
    "                            \"source\": \"IMF\",\n",
    "                        }\n",
    "                    )\n",
    "            return pd.DataFrame(records)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Parse error IMF {indicator}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    @timer(operation_name=\"IMF.collect_all\", track_metrics=True)\n",
    "    def collect_data(self, indicators: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        indicators = indicators or self.config.DEFAULT_IMF_INDICATORS\n",
    "        self.logger.info(f\"💰 Start IMF collection ({len(indicators)} indicators)\")\n",
    "        all_data = []\n",
    "        with track_progress(indicators, desc=\"IMF\", unit=\"indicator\") as pbar:\n",
    "            for indicator in pbar:\n",
    "                pbar.set_postfix_str(f\"Indicator: {indicator}\")\n",
    "                df = self._fetch_indicator_data(indicator)\n",
    "                if not df.empty:\n",
    "                    all_data.append(df)\n",
    "                    self.logger.info(f\"✅ {len(df)} records collected\")\n",
    "                time.sleep(self.config.DELAY_BETWEEN_REQUESTS)\n",
    "\n",
    "        result = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "        metric = PerformanceMetrics(\n",
    "            operation_name=\"IMF.collect_summary\",\n",
    "            start_time=datetime.now(),\n",
    "            items_processed=len(result),\n",
    "        )\n",
    "        metric.finalize(items=len(result))\n",
    "        _global_tracker.add_metric(metric)\n",
    "        self.logger.info(f\"✅ IMF done: {len(result)} records\")\n",
    "        return result"
   ],
   "id": "dc19ceb623107bda",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:38.475103Z",
     "start_time": "2025-10-17T21:55:38.431126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class WHOCollector(AbstractCollector):\n",
    "    \"\"\"\n",
    "    Handles the process of collecting data from the WHO's Global Health Observatory (GHO) API.\n",
    "\n",
    "    Provides functionality to fetch specific health indicator data, parse it into a structured format,\n",
    "    and aggregate data for multiple indicators. Ideal for automating the retrieval and handling of WHO's\n",
    "    health statistics.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    config : Config\n",
    "        The configuration required to access the WHO API, including URLs, default indicators, and\n",
    "        request delay settings.\n",
    "    logger : Logger\n",
    "        Logger instance for recording the progress and any issues during the collection process.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    _parse_who_data(data: Dict, indicator: str) -> List[Dict]\n",
    "        Parses raw WHO API response data and extracts relevant fields into a structured format.\n",
    "\n",
    "    _fetch_indicator_data(indicator: str) -> pd.DataFrame\n",
    "        Fetches data for a specific health indicator from the WHO API, returning it as a DataFrame.\n",
    "\n",
    "    collect_data(indicators: Optional[List[str]] = None) -> pd.DataFrame\n",
    "        Collects data for multiple WHO health indicators, aggregates it, and returns the result as\n",
    "        a unified DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "    def _parse_who_data(self, data: Dict, indicator: str) -> List[Dict]:\n",
    "        records = []\n",
    "        for item in data.get(\"value\", []):\n",
    "            records.append(\n",
    "                {\n",
    "                    \"indicator_code\": indicator,\n",
    "                    \"indicator_name\": item.get(\"IndicatorCode\"),\n",
    "                    \"country_code\": item.get(\"SpatialDim\"),\n",
    "                    \"year\": pd.to_numeric(item.get(\"TimeDim\"), errors=\"coerce\"),\n",
    "                    \"value\": pd.to_numeric(item.get(\"NumericValue\"), errors=\"coerce\"),\n",
    "                    \"source\": \"WHO GHO\",\n",
    "                }\n",
    "            )\n",
    "        return records\n",
    "\n",
    "    @timer(operation_name=\"WHO.fetch_indicator\", track_metrics=True)\n",
    "    def _fetch_indicator_data(self, indicator: str) -> pd.DataFrame:\n",
    "        url = f\"{self.config.OMS_API_URL}/{indicator}\"\n",
    "        params = {\"$filter\": f\"SpatialDim eq '{self.config.COUNTRY_CODE}'\"}\n",
    "        response, success = self._make_request_with_retry(url, params=params)\n",
    "        if not success or response is None:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            data = response.json()\n",
    "            records = self._parse_who_data(data, indicator)\n",
    "            return pd.DataFrame(records)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ Parse error WHO {indicator}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    @timer(operation_name=\"WHO.collect_all\", track_metrics=True)\n",
    "    def collect_data(self, indicators: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        indicators = indicators or self.config.DEFAULT_HEALTH_INDICATORS\n",
    "        self.logger.info(f\"🏥 Start WHO collection ({len(indicators)} indicators)\")\n",
    "        all_data = []\n",
    "        with track_progress(indicators, desc=\"WHO\", unit=\"indicator\") as pbar:\n",
    "            for indicator in pbar:\n",
    "                pbar.set_postfix_str(f\"Indicator: {indicator}\")\n",
    "                df = self._fetch_indicator_data(indicator)\n",
    "                if not df.empty:\n",
    "                    all_data.append(df)\n",
    "                    self.logger.info(f\"✅ {len(df)} records collected\")\n",
    "                time.sleep(self.config.DELAY_BETWEEN_REQUESTS)\n",
    "\n",
    "        result = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "        metric = PerformanceMetrics(\n",
    "            operation_name=\"WHO.collect_summary\",\n",
    "            start_time=datetime.now(),\n",
    "            items_processed=len(result),\n",
    "        )\n",
    "        metric.finalize(items=len(result))\n",
    "        _global_tracker.add_metric(metric)\n",
    "        self.logger.info(f\"✅ WHO done: {len(result)} records\")\n",
    "        return result"
   ],
   "id": "834a9e28cee88e31",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:38.537116Z",
     "start_time": "2025-10-17T21:55:38.526178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class UNDPCollector(AbstractCollector):\n",
    "    \"\"\"\n",
    "    Collects and processes data from the UNDP API.\n",
    "\n",
    "    This class is responsible for retrieving data from the UNDP's API, filtering\n",
    "    it to include only records relevant to the configured country code, and\n",
    "    finalizing performance metrics based on the collected data. It is a concrete\n",
    "    implementation of the AbstractCollector class.\n",
    "\n",
    "    Methods:\n",
    "        collect_data: Fetches data from the UNDP API, filters data for a specific\n",
    "        country based on a configuration, and calculates performance metrics.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "    \"\"\"\n",
    "    @timer(operation_name=\"UNDP.collect_all\", track_metrics=True)\n",
    "    def collect_data(self) -> pd.DataFrame:\n",
    "        self.logger.info(\"🌐 Start UNDP collection\")\n",
    "        url = self.config.UNDP_API_URL\n",
    "        response, success = self._make_request_with_retry(url)\n",
    "        if not success or response is None:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            from io import BytesIO\n",
    "\n",
    "            df = pd.read_csv(BytesIO(response.content))\n",
    "            df_benin = df[df[\"iso3\"] == self.config.COUNTRY_CODE].copy()\n",
    "            df_benin[\"source\"] = \"UNDP HDR\"\n",
    "            metric = PerformanceMetrics(\n",
    "                operation_name=\"UNDP.collect_summary\",\n",
    "                start_time=datetime.now(),\n",
    "                items_processed=len(df_benin),\n",
    "            )\n",
    "            metric.finalize(items=len(df_benin))\n",
    "            _global_tracker.add_metric(metric)\n",
    "            self.logger.info(f\"✅ UNDP: {len(df_benin)} records\")\n",
    "            return df_benin\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ UNDP error: {e}\")\n",
    "            return pd.DataFrame()"
   ],
   "id": "47cce11b78c576c7",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:38.623911Z",
     "start_time": "2025-10-17T21:55:38.592077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class INSAECollector(AbstractCollector):\n",
    "    \"\"\"\n",
    "    Defines the INSAECollector class for collecting and processing data from\n",
    "    INSAE (Institut National de la Statistique et de l’Analyse Économique). This\n",
    "    class is responsible for downloading and aggregating data from various Excel\n",
    "    and CSV files available at specified URLs.\n",
    "\n",
    "    The class provides methods to scrape and collect data from predefined sources,\n",
    "    parse the downloaded file contents, handle various exceptions during file\n",
    "    processing, and consolidate the fetched data into a single Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    @timer(operation_name=\"INSAE.download_file\", track_metrics=True)\n",
    "    def _download_excel_or_csv(self, url: str) -> pd.DataFrame:\n",
    "        response, success = self._make_request_with_retry(url)\n",
    "        if not success or response is None:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            from io import BytesIO\n",
    "\n",
    "            if url.endswith(\".csv\"):\n",
    "                return pd.read_csv(BytesIO(response.content))\n",
    "            else:\n",
    "                return pd.read_excel(BytesIO(response.content), engine=\"openpyxl\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ File read error: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    @timer(operation_name=\"INSAE.scrape_source\", track_metrics=True)\n",
    "    def _scrape_insae_data(self, url: str, source: str) -> pd.DataFrame:\n",
    "        response, success = self._make_request_with_retry(url)\n",
    "        if not success or response is None:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            import re\n",
    "            from urllib.parse import urljoin\n",
    "\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            download_links = soup.find_all(\"a\", href=re.compile(r\"\\.(xlsx?|csv)$\"))\n",
    "            data_frames = []\n",
    "            links_to_process = download_links[:5]\n",
    "            with track_progress(\n",
    "                    links_to_process, desc=f\"INSAE {source}\", unit=\"file\"\n",
    "            ) as pbar:\n",
    "                for link in pbar:\n",
    "                    file_url = urljoin(url, link[\"href\"])\n",
    "                    pbar.set_postfix_str(f\"File: {link.get_text(strip=True)[:30]}\")\n",
    "                    self.logger.info(f\"📥 Downloading: {file_url}\")\n",
    "                    file_df = self._download_excel_or_csv(file_url)\n",
    "                    if not file_df.empty:\n",
    "                        file_df[\"source\"] = f\"INSAE - {source}\"\n",
    "                        data_frames.append(file_df)\n",
    "            return (\n",
    "                pd.concat(data_frames, ignore_index=True)\n",
    "                if data_frames\n",
    "                else pd.DataFrame()\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"❌ INSAE scraping error: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    @timer(operation_name=\"INSAE.collect_all\", track_metrics=True)\n",
    "    def collect_data(self) -> pd.DataFrame:\n",
    "        self.logger.info(\"🇧🇯 Start INSAE Bénin collection\")\n",
    "        insae_urls = self.config.EXTERNAL_SCRAPING_URLS\n",
    "        all_data = []\n",
    "        with track_progress(\n",
    "                insae_urls.items(), desc=\"INSAE sources\", unit=\"source\"\n",
    "        ) as pbar:\n",
    "            for source_name, url in pbar:\n",
    "                if not source_name.startswith((\"rgph\", \"edc\", \"emicov\")):\n",
    "                    continue\n",
    "                pbar.set_postfix_str(f\"Source: {source_name}\")\n",
    "                df = self._scrape_insae_data(url, source_name)\n",
    "                if not df.empty:\n",
    "                    all_data.append(df)\n",
    "\n",
    "        result = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "        metric = PerformanceMetrics(\n",
    "            operation_name=\"INSAE.collect_summary\",\n",
    "            start_time=datetime.now(),\n",
    "            items_processed=len(result),\n",
    "        )\n",
    "        metric.finalize(items=len(result))\n",
    "        _global_tracker.add_metric(metric)\n",
    "        self.logger.info(f\"✅ INSAE done: {len(result)} records\")\n",
    "        return result"
   ],
   "id": "de67e3e4aa97debb",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:38.739502Z",
     "start_time": "2025-10-17T21:55:38.669921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataCleaner:\n",
    "    \"\"\"\n",
    "    Provides a framework for cleaning and preprocessing data.\n",
    "\n",
    "    The class is designed to standardize and clean datasets across various domains.\n",
    "    It provides capabilities for removing duplicates, handling null values,\n",
    "    standardizing column names, converting data types, removing outliers, and more.\n",
    "    It can also perform specific cleaning operations for World Bank data and\n",
    "    geographic data. A cleaning summary can be generated to review the results\n",
    "    of operations performed.\n",
    "\n",
    "    Attributes:\n",
    "        config: The configuration dictionary for the cleaning process.\n",
    "        reports: A dictionary holding the cleaning reports for datasets.\n",
    "\n",
    "    Methods:\n",
    "        clean_dataset(df, source_name):\n",
    "            Cleans the provided dataset with various preprocessing operations.\n",
    "        clean_world_bank_data(df):\n",
    "            Cleans World Bank-specific data with rules specific to such datasets.\n",
    "        clean_geographic_data(df):\n",
    "            Cleans geographic-specific data, including latitude and longitude validation.\n",
    "        generate_cleaning_summary():\n",
    "            Generates a summary DataFrame of all cleaning processes performed.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: Optional[Dict] = None):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.config = config or self._default_config()\n",
    "        self.reports: Dict[str, CleaningReport] = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def _default_config() -> Dict:\n",
    "        return {\n",
    "            \"remove_duplicates\": True,\n",
    "            \"handle_nulls\": True,\n",
    "            \"null_threshold\": 0.7,\n",
    "            \"detect_outliers\": True,\n",
    "            \"outlier_method\": \"iqr\",\n",
    "            \"outlier_threshold\": 3,\n",
    "            \"standardize_text\": True,\n",
    "            \"standardize_dates\": True,\n",
    "            \"convert_types\": True,\n",
    "            \"remove_empty_strings\": True,\n",
    "        }\n",
    "\n",
    "    def _standardize_column_names(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        import re\n",
    "\n",
    "        new_columns = {}\n",
    "        for col in df.columns:\n",
    "            new_col = str(col).lower()\n",
    "            new_col = re.sub(r\"[^\\w\\s]\", \"\", new_col)\n",
    "            new_col = re.sub(r\"\\s+\", \"_\", new_col)\n",
    "            new_col = re.sub(r\"_+\", \"_\", new_col).strip(\"_\")\n",
    "            new_columns[col] = new_col\n",
    "        df = df.rename(columns=new_columns)\n",
    "        self.logger.info(f\"✅ {len(new_columns)} columns standardized\")\n",
    "        return df\n",
    "\n",
    "    def _remove_duplicates(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, int]:\n",
    "        initial_count = len(df)\n",
    "        df = df.drop_duplicates()\n",
    "        duplicates_removed = initial_count - len(df)\n",
    "        if duplicates_removed > 0:\n",
    "            self.logger.info(f\"🗑️ {duplicates_removed} duplicates removed\")\n",
    "        return df, duplicates_removed\n",
    "\n",
    "    def _clean_text_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        text_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "        for col in text_cols:\n",
    "            df[col] = df[col].str.strip()\n",
    "            if self.config.get(\"remove_empty_strings\"):\n",
    "                df[col] = df[col].replace(\"\", np.nan)\n",
    "                df[col] = df[col].replace(r\"^\\s*$\", np.nan, regex=True)\n",
    "        return df\n",
    "\n",
    "    def _convert_data_types(\n",
    "            self, df: pd.DataFrame\n",
    "    ) -> Tuple[pd.DataFrame, Dict[str, str]]:\n",
    "        conversions = {}\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                original_type = str(df[col].dtype)\n",
    "                numeric_vals = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "                if numeric_vals.notna().sum() / len(df) > 0.8:\n",
    "                    df[col] = numeric_vals\n",
    "                    conversions[col] = f\"{original_type} -> numeric\"\n",
    "                    continue\n",
    "                try:\n",
    "                    date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "                    if date_vals.notna().sum() / len(df) > 0.8:\n",
    "                        df[col] = date_vals\n",
    "                        conversions[col] = f\"{original_type} -> datetime\"\n",
    "                except:\n",
    "                    pass\n",
    "        if conversions:\n",
    "            self.logger.info(f\"🔄 {len(conversions)} type conversions\")\n",
    "        return df, conversions\n",
    "\n",
    "    def _remove_empty_columns(\n",
    "            self, df: pd.DataFrame, report: CleaningReport\n",
    "    ) -> Tuple[pd.DataFrame, List[str]]:\n",
    "        threshold = self.config.get(\"null_threshold\", 0.7)\n",
    "        dropped_cols = []\n",
    "        for col in df.columns:\n",
    "            null_ratio = df[col].isnull().sum() / len(df)\n",
    "            if null_ratio > threshold:\n",
    "                dropped_cols.append(col)\n",
    "                report.issues_detected.append(\n",
    "                    f\"Column '{col}' dropped: {null_ratio:.1%} missing values\"\n",
    "                )\n",
    "        if dropped_cols:\n",
    "            df = df.drop(columns=dropped_cols)\n",
    "            self.logger.warning(f\"⚠️ {len(dropped_cols)} columns dropped\")\n",
    "        return df, dropped_cols\n",
    "\n",
    "    def _handle_outliers(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, int]:\n",
    "        if not self.config.get(\"detect_outliers\"):\n",
    "            return df, 0\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        outliers_removed = 0\n",
    "        for col in numeric_cols:\n",
    "            if df[col].notna().sum() < 10:\n",
    "                continue\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outliers_mask = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "            outliers_count = outliers_mask.sum()\n",
    "            if outliers_count > 0:\n",
    "                df.loc[outliers_mask, col] = np.nan\n",
    "                outliers_removed += outliers_count\n",
    "        if outliers_removed > 0:\n",
    "            self.logger.info(f\"🔍 {outliers_removed} outliers handled\")\n",
    "        return df, outliers_removed\n",
    "\n",
    "    @timer(operation_name=\"DataCleaner.clean_dataset\", track_metrics=True)\n",
    "    def clean_dataset(\n",
    "            self, df: pd.DataFrame, source_name: str\n",
    "    ) -> Tuple[pd.DataFrame, CleaningReport]:\n",
    "        self.logger.info(f\"🧹 Cleaning: {source_name}\")\n",
    "        report = CleaningReport(\n",
    "            source=source_name, initial_rows=len(df), final_rows=len(df)\n",
    "        )\n",
    "        df = self._standardize_column_names(df)\n",
    "        report.columns_standardized = df.columns.tolist()\n",
    "        df, duplicates = self._remove_duplicates(df)\n",
    "        report.duplicates_removed = duplicates\n",
    "        df = self._clean_text_columns(df)\n",
    "        df, dropped_cols = self._remove_empty_columns(df, report)\n",
    "        report.columns_dropped = dropped_cols\n",
    "        df, conversions = self._convert_data_types(df)\n",
    "        report.data_types_converted = conversions\n",
    "        df, outliers = self._handle_outliers(df)\n",
    "        report.outliers_removed = outliers\n",
    "        report.final_rows = len(df)\n",
    "        report.rows_removed = report.initial_rows - report.final_rows\n",
    "        self.reports[source_name] = report\n",
    "        self.logger.info(\n",
    "            f\"✅ Cleaning done: {report.initial_rows} → {report.final_rows} rows ({report.rows_removed} removed)\"\n",
    "        )\n",
    "        return df, report\n",
    "\n",
    "    def clean_world_bank_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        self.logger.info(\"🌍 World Bank specific cleaning\")\n",
    "        df = df.dropna(subset=[\"value\"])\n",
    "        df = df[(df[\"year\"] >= 1900) & (df[\"year\"] <= datetime.now().year)]\n",
    "        df = df[df[\"value\"] >= 0]\n",
    "        return df\n",
    "\n",
    "    def clean_geographic_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        self.logger.info(\"🗺️ Geographic specific cleaning\")\n",
    "        df = df.dropna(subset=[\"name\"])\n",
    "        if \"latitude\" in df.columns and \"longitude\" in df.columns:\n",
    "            df = df[\n",
    "                (df[\"latitude\"].between(-90, 90)) & (df[\"longitude\"].between(-180, 180))\n",
    "                ]\n",
    "        return df\n",
    "\n",
    "    def generate_cleaning_summary(self) -> pd.DataFrame:\n",
    "        if not self.reports:\n",
    "            self.logger.warning(\"⚠️ No cleaning reports available\")\n",
    "            return pd.DataFrame()\n",
    "        summary_data = [report.to_dict() for report in self.reports.values()]\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        self.logger.info(\"📊 Cleaning summary generated\")\n",
    "        return summary_df"
   ],
   "id": "18d4fa491ff0b7ea",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:38.989601Z",
     "start_time": "2025-10-17T21:55:38.768224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataCollectorOrchestrator:\n",
    "    \"\"\"\n",
    "    Handles the orchestration of data collection, cleaning, and consolidation\n",
    "    operations by coordinating with different data collectors and processing tools.\n",
    "\n",
    "    The class is responsible for initializing, organizing, and managing the workflow\n",
    "    pipeline for collecting raw data from various sources, cleaning it using defined\n",
    "    cleaning routines, and consolidating final datasets into structured outputs. It\n",
    "    supports a configurable and extendable workflow, facilitating data operations\n",
    "    such as storage, tracking progress, and logging.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, config: Optional[GlobalConfig] = None, base_dir: Optional[Path] = None\n",
    "    ):\n",
    "        self.config = config or GlobalConfig()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.directory_manager = DirectoryManager(base_dir)\n",
    "        self.directories = self.directory_manager.initialize_structure_directory()\n",
    "        self.collectors = {\n",
    "            \"world_bank\": WorldBankCollector(self.config),\n",
    "            \"imf\": IMFCollector(self.config),\n",
    "            \"who\": WHOCollector(self.config),\n",
    "            \"undp\": UNDPCollector(self.config),\n",
    "            \"insae\": INSAECollector(self.config),\n",
    "            \"web_scraping\": WebScrapingCollector(self.config),\n",
    "            \"geographic\": GeographicCollector(self.config),\n",
    "            \"external\": ExternalCollector(self.config),\n",
    "        }\n",
    "        self.cleaner = DataCleaner()\n",
    "    \n",
    "    def consolidate_final_data(\n",
    "        self, cleaned_data: Dict[str, pd.DataFrame]\n",
    "    ) -> Dict[str, pd.DataFrame]:\n",
    "        self.logger.info(\"🔗 Consolidating final datasets\")\n",
    "        final_datasets = {}\n",
    "        \n",
    "        economic_sources = ['world_bank', 'imf']\n",
    "        economic_data = []\n",
    "        for source in economic_sources:\n",
    "            if source in cleaned_data and not cleaned_data[source].empty:\n",
    "                df = cleaned_data[source].copy()\n",
    "                df['data_source'] = source\n",
    "                economic_data.append(df)\n",
    "        \n",
    "        if economic_data:\n",
    "            economic_consolidated = pd.concat(economic_data, ignore_index=True)\n",
    "            final_datasets['economic_indicators'] = economic_consolidated\n",
    "            filepath = self.directories['final_data'] / 'economic_indicators.csv'\n",
    "            economic_consolidated.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            self.logger.info(f\"💾 Saved: {filepath.name}\")\n",
    "        \n",
    "        health_sources = ['who']\n",
    "        health_data = []\n",
    "        for source in health_sources:\n",
    "            if source in cleaned_data and not cleaned_data[source].empty:\n",
    "                df = cleaned_data[source].copy()\n",
    "                df['data_source'] = source\n",
    "                health_data.append(df)\n",
    "        \n",
    "        if health_data:\n",
    "            health_consolidated = pd.concat(health_data, ignore_index=True)\n",
    "            final_datasets['health_indicators'] = health_consolidated\n",
    "            filepath = self.directories['final_data'] / 'health_indicators.csv'\n",
    "            health_consolidated.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            self.logger.info(f\"💾 Saved: {filepath.name}\")\n",
    "        \n",
    "        geo_sources = [k for k in cleaned_data.keys() if 'geographic' in k]\n",
    "        for source in geo_sources:\n",
    "            if source in cleaned_data and not cleaned_data[source].empty:\n",
    "                df = cleaned_data[source].copy()\n",
    "                final_datasets[source] = df\n",
    "                filepath = self.directories['final_data'] / f'{source}.csv'\n",
    "                df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "                self.logger.info(f\"💾 Saved: {filepath.name}\")\n",
    "        \n",
    "        other_sources = [k for k in cleaned_data.keys() \n",
    "                        if k not in economic_sources + health_sources + geo_sources]\n",
    "        for source in other_sources:\n",
    "            if source in cleaned_data and not cleaned_data[source].empty:\n",
    "                df = cleaned_data[source].copy()\n",
    "                final_datasets[source] = df\n",
    "                filepath = self.directories['final_data'] / f'{source}.csv'\n",
    "                df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "                self.logger.info(f\"💾 Saved: {filepath.name}\")\n",
    "        \n",
    "        self.logger.info(f\"✅ {len(final_datasets)} final datasets created\")\n",
    "        return final_datasets\n",
    "\n",
    "    @timer(operation_name=\"Orchestrator.full_collection\", track_metrics=True)\n",
    "    def run_full_collection(\n",
    "            self, collectors: Optional[List[str]] = None\n",
    "    ) -> Dict[str, pd.DataFrame]:\n",
    "        collectors = collectors or list(self.collectors.keys())\n",
    "        results = {}\n",
    "        self.logger.info(f\"🚀 Starting collection ({len(collectors)} collectors)\")\n",
    "        with track_progress(\n",
    "                collectors, desc=\"Global collection\", unit=\"collector\"\n",
    "        ) as pbar:\n",
    "            for collector_name in pbar:\n",
    "                if collector_name not in self.collectors:\n",
    "                    self.logger.warning(f\"⚠️ Unknown collector: {collector_name}\")\n",
    "                    continue\n",
    "                pbar.set_postfix_str(f\"Collector: {collector_name}\")\n",
    "                self.logger.info(f\"▶️ Starting: {collector_name}\")\n",
    "                try:\n",
    "                    collector = self.collectors[collector_name]\n",
    "                    data = collector.collect_data()\n",
    "                    if collector_name == \"geographic\" and isinstance(data, dict):\n",
    "                        for key, df in data.items():\n",
    "                            if not df.empty:\n",
    "                                filename = f\"{collector_name}_{key}.csv\"\n",
    "                                filepath = self.directories[\"raw\"] / filename\n",
    "                                collector.save_data(df, filepath)\n",
    "                                results[f\"{collector_name}_{key}\"] = df\n",
    "                        combined = pd.concat(\n",
    "                            [df for df in data.values() if not df.empty],\n",
    "                            ignore_index=True,\n",
    "                        )\n",
    "                        if not combined.empty:\n",
    "                            results[collector_name] = combined\n",
    "                    elif isinstance(data, pd.DataFrame) and not data.empty:\n",
    "                        results[collector_name] = data\n",
    "                        filename = f\"{collector_name}_data.csv\"\n",
    "                        filepath = self.directories[\"raw\"] / filename\n",
    "                        collector.save_data(data, filepath)\n",
    "                    record_count = (\n",
    "                        len(data)\n",
    "                        if isinstance(data, pd.DataFrame)\n",
    "                        else sum(\n",
    "                            len(df)\n",
    "                            for df in data.values()\n",
    "                            if isinstance(df, pd.DataFrame)\n",
    "                        )\n",
    "                    )\n",
    "                    self.logger.info(f\"✅ {collector_name}: {record_count} records\")\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"❌ Error {collector_name}: {e}\", exc_info=True)\n",
    "        total_records = sum(\n",
    "            len(df) for df in results.values() if isinstance(df, pd.DataFrame)\n",
    "        )\n",
    "        self.logger.info(f\"🏁 Collection done: {total_records} records\")\n",
    "        return results\n",
    "\n",
    "    @timer(operation_name=\"Orchestrator.full_cleaning\", track_metrics=True)\n",
    "    def run_full_cleaning(\n",
    "            self, raw_data: Dict[str, pd.DataFrame]\n",
    "    ) -> Dict[str, pd.DataFrame]:\n",
    "        self.logger.info(f\"🧹 Start cleaning ({len(raw_data)} sources)\")\n",
    "        cleaned_data = {}\n",
    "        with track_progress(raw_data.items(), desc=\"Cleaning\", unit=\"source\") as pbar:\n",
    "            for source_name, df in pbar:\n",
    "                if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "                    continue\n",
    "                pbar.set_postfix_str(f\"Source: {source_name}\")\n",
    "                try:\n",
    "                    cleaned_df, report = self.cleaner.clean_dataset(df, source_name)\n",
    "                    if \"world_bank\" in source_name.lower():\n",
    "                        cleaned_df = self.cleaner.clean_world_bank_data(cleaned_df)\n",
    "                    elif \"geographic\" in source_name.lower():\n",
    "                        cleaned_df = self.cleaner.clean_geographic_data(cleaned_df)\n",
    "                    if not cleaned_df.empty:\n",
    "                        cleaned_data[source_name] = cleaned_df\n",
    "                        filepath = (\n",
    "                                self.directories[\"processed\"] / f\"{source_name}_cleaned.csv\"\n",
    "                        )\n",
    "                        cleaned_df.to_csv(filepath, index=False, encoding=\"utf-8\")\n",
    "                        self.logger.info(f\"💾 Saved: {filepath.name}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"❌ Cleaning error {source_name}: {e}\")\n",
    "        self.logger.info(f\"✅ Cleaning done: {len(cleaned_data)} sources processed\")\n",
    "        return cleaned_data\n",
    "\n",
    "    def generate_collection_summary(\n",
    "            self, data: Dict[str, pd.DataFrame]\n",
    "    ) -> pd.DataFrame:\n",
    "        summary = []\n",
    "        for source, df in data.items():\n",
    "            if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "                continue\n",
    "            numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "            date_cols = df.select_dtypes(include=[\"datetime64\"]).columns\n",
    "            summary.append(\n",
    "                {\n",
    "                    \"source\": source,\n",
    "                    \"records\": len(df),\n",
    "                    \"columns\": len(df.columns),\n",
    "                    \"memory_mb\": round(df.memory_usage(deep=True).sum() / (1024 ** 2), 2),\n",
    "                    \"has_nulls\": df.isnull().any().any(),\n",
    "                    \"null_pct\": round(\n",
    "                        df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100, 2\n",
    "                    ),\n",
    "                    \"numeric_cols\": len(numeric_cols),\n",
    "                    \"date_cols\": len(date_cols),\n",
    "                    \"duplicates\": df.duplicated().sum(),\n",
    "                    \"date\": datetime.now().date(),\n",
    "                }\n",
    "            )\n",
    "        summary_df = pd.DataFrame(summary)\n",
    "        if not summary_df.empty:\n",
    "            filepath = self.directories[\"processed\"] / \"collection_summary.csv\"\n",
    "            summary_df.to_csv(filepath, index=False, encoding=\"utf-8\")\n",
    "            print(\"\\n\" + \"=\" * 100)\n",
    "            print(\"📊 COLLECTION SUMMARY\")\n",
    "            print(\"=\" * 100)\n",
    "            print(summary_df.to_string(index=False))\n",
    "            print(\"=\" * 100 + \"\\n\")\n",
    "        return summary_df\n",
    "\n",
    "    def validate_data_quality(\n",
    "            self, data: Dict[str, pd.DataFrame]\n",
    "    ) -> Dict[str, List[str]]:\n",
    "        self.logger.info(\"🔍 Data quality validation\")\n",
    "        issues = {}\n",
    "        for source, df in data.items():\n",
    "            if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "                continue\n",
    "            source_issues = []\n",
    "            dup_count = df.duplicated().sum()\n",
    "            if dup_count > 0:\n",
    "                source_issues.append(f\"Duplicates: {dup_count}\")\n",
    "            high_null_cols = df.columns[df.isnull().sum() / len(df) > 0.5]\n",
    "            if len(high_null_cols) > 0:\n",
    "                source_issues.append(f\"Columns >50% nulls: {list(high_null_cols)}\")\n",
    "            if \"year\" in df.columns:\n",
    "                invalid_years = df[(df[\"year\"] < 1900) | (df[\"year\"] > 2025)]\n",
    "                if len(invalid_years) > 0:\n",
    "                    source_issues.append(f\"Invalid years: {len(invalid_years)}\")\n",
    "            if source_issues:\n",
    "                issues[source] = source_issues\n",
    "        if issues:\n",
    "            self.logger.warning(f\"⚠️ Issues detected in {len(issues)} sources\")\n",
    "            for source, issue_list in issues.items():\n",
    "                for issue in issue_list:\n",
    "                    self.logger.warning(f\"  - {source}: {issue}\")\n",
    "        else:\n",
    "            self.logger.info(\"✅ No quality issues detected\")\n",
    "        return issues\n",
    "\n",
    "    def create_data_dictionary(self, data: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "        self.logger.info(\"📖 Creating data dictionary\")\n",
    "        dictionary = []\n",
    "        for source, df in data.items():\n",
    "            if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "                continue\n",
    "            for col in df.columns:\n",
    "                entry = {\n",
    "                    \"source\": source,\n",
    "                    \"variable\": col,\n",
    "                    \"type\": str(df[col].dtype),\n",
    "                    \"non_null_count\": df[col].notna().sum(),\n",
    "                    \"null_count\": df[col].isnull().sum(),\n",
    "                    \"null_pct\": round(df[col].isnull().sum() / len(df) * 100, 2),\n",
    "                    \"unique_values\": df[col].nunique(),\n",
    "                }\n",
    "                if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                    entry.update(\n",
    "                        {\n",
    "                            \"min\": df[col].min(),\n",
    "                            \"max\": df[col].max(),\n",
    "                            \"mean\": round(df[col].mean(), 2),\n",
    "                            \"median\": df[col].median(),\n",
    "                        }\n",
    "                    )\n",
    "                dictionary.append(entry)\n",
    "        dict_df = pd.DataFrame(dictionary)\n",
    "        if not dict_df.empty:\n",
    "            filepath = self.directories[\"docs\"] / \"data_dictionary.csv\"\n",
    "            dict_df.to_csv(filepath, index=False, encoding=\"utf-8\")\n",
    "            self.logger.info(f\"💾 Dictionary saved: {filepath}\")\n",
    "        return dict_df\n",
    "\n",
    "    @timer(operation_name=\"Orchestrator.complete_pipeline\", track_metrics=True)\n",
    "    def run_complete_pipeline(self) -> Dict[str, Any]:\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"🚀 STARTING COMPLETE ANIP PIPELINE\")\n",
    "        print(\"=\" * 100 + \"\\n\")\n",
    "        print(\"📡 STEP 1/4: DATA COLLECTION\")\n",
    "        print(\"-\" * 100)\n",
    "        raw_data = self.run_full_collection()\n",
    "        print(\"\\n🔍 STEP 2/4: INITIAL VALIDATION\")\n",
    "        print(\"-\" * 100)\n",
    "        initial_issues = self.validate_data_quality(raw_data)\n",
    "        print(\"\\n🧹 STEP 3/4: DATA CLEANING\")\n",
    "        print(\"-\" * 100)\n",
    "        cleaned_data = self.run_full_cleaning(raw_data)\n",
    "        print(\"\\n📊 STEP 4/4: GENERATING DELIVERABLES\")\n",
    "        print(\"-\" * 100)\n",
    "        collection_summary = self.generate_collection_summary(cleaned_data)\n",
    "        cleaning_summary = self.cleaner.generate_cleaning_summary()\n",
    "        data_dictionary = self.create_data_dictionary(cleaned_data)\n",
    "        \n",
    "        print(\"\\n🔗 STEP 5/5: CONSOLIDATION & EXPORT\")\n",
    "        print(\"-\" * 100)\n",
    "        final_datasets = self.consolidate_final_data(cleaned_data)\n",
    "        \n",
    "        final_issues = self.validate_data_quality(cleaned_data)\n",
    "        if not cleaning_summary.empty:\n",
    "            filepath = self.directories[\"processed\"] / \"cleaning_summary.csv\"\n",
    "            cleaning_summary.to_csv(filepath, index=False, encoding=\"utf-8\")\n",
    "            print(f\"\\n💾 Cleaning summary: {filepath}\")\n",
    "            print(\"\\n\" + cleaning_summary.to_string(index=False))\n",
    "        _global_tracker.print_summary()\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"✅ PIPELINE COMPLETED\")\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"📂 Raw data: {self.directories['raw']}\")\n",
    "        print(f\"📂 Cleaned data: {self.directories['processed']}\")\n",
    "        print(f\"📂 Final data: {self.directories['final_data']}\")\n",
    "        print(f\"📂 Documentation: {self.directories['docs']}\")\n",
    "        print(\"=\" * 100 + \"\\n\")\n",
    "        return {\n",
    "            \"raw_data\": raw_data,\n",
    "            \"cleaned_data\": cleaned_data,\n",
    "            \"final_datasets\": final_datasets,\n",
    "            \"collection_summary\": collection_summary,\n",
    "            \"cleaning_summary\": cleaning_summary,\n",
    "            \"data_dictionary\": data_dictionary,\n",
    "            \"initial_issues\": initial_issues,\n",
    "            \"final_issues\": final_issues,\n",
    "            \"performance_metrics\": _global_tracker.get_summary(),\n",
    "        }"
   ],
   "id": "75ea4dca877b9d21",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:55:39.048624Z",
     "start_time": "2025-10-17T21:55:39.021684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@timer(operation_name=\"Main.execution\", track_metrics=True)\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Executes the main data collection, cleaning, and processing pipeline, and provides\n",
    "    summary results and performance metrics.\n",
    "\n",
    "    This function serves as the main entry point for orchestrating the entire data workflow.\n",
    "    It initializes the environment, executes the complete pipeline, logs detailed performance\n",
    "    metrics, and displays a summary of the processing results. The function tracks the performance\n",
    "    of operations and maintains a record of any remaining quality issues.\n",
    "\n",
    "    Parameters:\n",
    "    operation_name (str): The name of the operation being timed, used for performance tracking.\n",
    "    track_metrics (bool): Whether to track and log performance metrics. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the results of the pipeline execution. Keys include:\n",
    "        - 'raw_data': List of collected raw data sources.\n",
    "        - 'cleaned_data': List of cleaned data sources.\n",
    "        - 'final_datasets': List of finalized datasets.\n",
    "        - 'data_dictionary': List of variables documented in the datasets.\n",
    "        - 'final_issues': List of sources with unresolved quality issues.\n",
    "        - 'performance_metrics': Dictionary with performance metrics, such as total duration,\n",
    "          number of successful and failed operations, and items processed.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If an error occurs during any phase of the data workflow.\n",
    "\n",
    "    Notes:\n",
    "    The function logs detailed performance metrics to a CSV file within the designated log\n",
    "    directory. The performance data includes operation-specific metrics such as execution\n",
    "    time and success rates.\n",
    "\n",
    "    See Also:\n",
    "    DataCollectorOrchestrator: Class responsible for orchestrating data collection and cleaning.\n",
    "    setup_environment: Initializes the necessary environment and logging setup.\n",
    "    _global_tracker: Tracks operational metrics for performance evaluations.\n",
    "    \"\"\"\n",
    "    setup_environment(log_dir=Path(\"logs\"))\n",
    "    orchestrator = DataCollectorOrchestrator()\n",
    "    results = orchestrator.run_complete_pipeline()\n",
    "    print(\"\\n📋 FINAL RESULTS:\")\n",
    "    print(f\"  - Sources collected: {len(results['raw_data'])}\")\n",
    "    print(f\"  - Sources cleaned: {len(results['cleaned_data'])}\")\n",
    "    print(f\"  - Final datasets: {len(results['final_datasets'])}\")\n",
    "    print(f\"  - Variables documented: {len(results['data_dictionary'])}\")\n",
    "    if results[\"final_issues\"]:\n",
    "        print(f\"  ⚠️ Remaining issues: {len(results['final_issues'])} sources\")\n",
    "    else:\n",
    "        print(\"  ✅ No quality issues detected\")\n",
    "    print(\"\\n⏱️ GLOBAL PERFORMANCE:\")\n",
    "    perf = results[\"performance_metrics\"]\n",
    "    print(f\"  - Total operations: {perf['total_operations']}\")\n",
    "    print(f\"  - Successful: {perf['successful']}\")\n",
    "    print(f\"  - Failed: {perf['failed']}\")\n",
    "    print(f\"  - Total duration: {perf['total_duration']}s\")\n",
    "    print(f\"  - Average duration: {perf['avg_duration']}s\")\n",
    "    print(f\"  - Items processed: {perf['total_items']}\")\n",
    "    performance_df = pd.DataFrame([m.to_dict() for m in _global_tracker.metrics])\n",
    "    perf_filepath = orchestrator.directories[\"logs\"] / \"performance_metrics.csv\"\n",
    "    performance_df.to_csv(perf_filepath, index=False, encoding=\"utf-8\")\n",
    "    print(f\"\\n💾 Performance metrics: {perf_filepath}\")\n",
    "    return results"
   ],
   "id": "1393abb468b4490a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T21:58:07.218400Z",
     "start_time": "2025-10-17T21:55:39.092029Z"
    }
   },
   "cell_type": "code",
   "source": "_ = main()",
   "id": "95599f5822e5d81d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-17 22:55:39 | INFO     | DirectoryManager | 7 dossiers créés avec succès.\n",
      "2025-10-17 22:55:39 | INFO     | __main__ | ⏱️  Start: Orchestrator.complete_pipeline\n",
      "2025-10-17 22:55:39 | INFO     | __main__ | ⏱️  Start: Orchestrator.full_collection\n",
      "2025-10-17 22:55:39 | INFO     | __main__ | 🚀 Starting collection (8 collectors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "🚀 STARTING COMPLETE ANIP PIPELINE\n",
      "====================================================================================================\n",
      "\n",
      "📡 STEP 1/4: DATA COLLECTION\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global collection:   0%|                                               | 0/8 [00:00<?, ?collector/s]2025-10-17 22:55:39 | INFO     | __main__ | ▶️ Starting: world_bank\n",
      "2025-10-17 22:55:39 | INFO     | __main__ | ⏱️  Start: WorldBank.collect_all\n",
      "2025-10-17 22:55:39 | INFO     | WorldBankCollector | 🌍 Start World Bank collection (8 indicators)\n",
      "\n",
      "World Bank:   0%|                                                      | 0/8 [00:00<?, ?indicator/s]\u001B[A\n",
      "World Bank:   0%|                                                      | 0/8 [00:00<?, ?indicator/s]\u001B[A2025-10-17 22:55:39 | INFO     | __main__ | ⏱️  Start: WorldBank.fetch_indicator\n",
      "2025-10-17 22:55:40 | INFO     | __main__ | ✅ Done: WorldBank.fetch_indicator in 1.488s\n",
      "2025-10-17 22:55:40 | INFO     | WorldBankCollector | ✅ 10 records collected\n",
      "\n",
      "World Bank:  12%|█████▊                                        | 1/8 [00:02<00:14,  2.00s/indicator]\u001B[A\n",
      "World Bank:  12%|█████▊                                        | 1/8 [00:02<00:14,  2.00s/indicator]\u001B[A2025-10-17 22:55:41 | INFO     | __main__ | ⏱️  Start: WorldBank.fetch_indicator\n",
      "2025-10-17 22:55:41 | INFO     | __main__ | ✅ Done: WorldBank.fetch_indicator in 0.806s\n",
      "2025-10-17 22:55:41 | INFO     | WorldBankCollector | ✅ 10 records collected\n",
      "\n",
      "World Bank:  25%|███████████▌                                  | 2/8 [00:03<00:09,  1.61s/indicator]\u001B[A\n",
      "World Bank:  25%|███████████▌                                  | 2/8 [00:03<00:09,  1.61s/indicator]\u001B[A2025-10-17 22:55:42 | INFO     | __main__ | ⏱️  Start: WorldBank.fetch_indicator\n",
      "2025-10-17 22:55:43 | INFO     | __main__ | ✅ Done: WorldBank.fetch_indicator in 0.904s\n",
      "2025-10-17 22:55:43 | INFO     | WorldBankCollector | ✅ 10 records collected\n",
      "\n",
      "World Bank:  38%|█████████████████▎                            | 3/8 [00:04<00:07,  1.53s/indicator]\u001B[A\n",
      "World Bank:  38%|█████████████████▎                            | 3/8 [00:04<00:07,  1.53s/indicator]\u001B[A2025-10-17 22:55:43 | INFO     | __main__ | ⏱️  Start: WorldBank.fetch_indicator\n",
      "2025-10-17 22:55:44 | INFO     | __main__ | ✅ Done: WorldBank.fetch_indicator in 0.825s\n",
      "2025-10-17 22:55:44 | INFO     | WorldBankCollector | ✅ 10 records collected\n",
      "\n",
      "World Bank:  50%|███████████████████████                       | 4/8 [00:06<00:05,  1.46s/indicator]\u001B[A\n",
      "World Bank:  50%|███████████████████████                       | 4/8 [00:06<00:05,  1.46s/indicator]\u001B[A2025-10-17 22:55:45 | INFO     | __main__ | ⏱️  Start: WorldBank.fetch_indicator\n",
      "2025-10-17 22:55:46 | INFO     | __main__ | ✅ Done: WorldBank.fetch_indicator in 0.790s\n",
      "2025-10-17 22:55:46 | INFO     | WorldBankCollector | ✅ 10 records collected\n",
      "\n",
      "World Bank:  62%|████████████████████████████▊                 | 5/8 [00:07<00:04,  1.41s/indicator]\u001B[A\n",
      "World Bank:  62%|████████████████████████████▊                 | 5/8 [00:07<00:04,  1.41s/indicator]\u001B[A2025-10-17 22:55:46 | INFO     | __main__ | ⏱️  Start: WorldBank.fetch_indicator\n",
      "2025-10-17 22:55:47 | INFO     | __main__ | ✅ Done: WorldBank.fetch_indicator in 0.851s\n",
      "2025-10-17 22:55:47 | INFO     | WorldBankCollector | ✅ 10 records collected\n",
      "\n",
      "World Bank:  75%|██████████████████████████████████▌           | 6/8 [00:08<00:02,  1.40s/indicator]\u001B[A\n",
      "World Bank:  75%|██████████████████████████████████▌           | 6/8 [00:08<00:02,  1.40s/indicator]\u001B[A2025-10-17 22:55:47 | INFO     | __main__ | ⏱️  Start: WorldBank.fetch_indicator\n",
      "2025-10-17 22:55:48 | INFO     | __main__ | ✅ Done: WorldBank.fetch_indicator in 0.787s\n",
      "2025-10-17 22:55:48 | INFO     | WorldBankCollector | ✅ 10 records collected\n",
      "\n",
      "World Bank:  88%|████████████████████████████████████████▎     | 7/8 [00:10<00:01,  1.37s/indicator]\u001B[A\n",
      "World Bank:  88%|████████████████████████████████████████▎     | 7/8 [00:10<00:01,  1.37s/indicator]\u001B[A2025-10-17 22:55:49 | INFO     | __main__ | ⏱️  Start: WorldBank.fetch_indicator\n",
      "2025-10-17 22:55:50 | INFO     | __main__ | ✅ Done: WorldBank.fetch_indicator in 0.803s\n",
      "2025-10-17 22:55:50 | INFO     | WorldBankCollector | ✅ 10 records collected\n",
      "\n",
      "World Bank: 100%|██████████████████████████████████████████████| 8/8 [00:11<00:00,  1.43s/indicator]\u001B[A\n",
      "2025-10-17 22:55:50 | INFO     | WorldBankCollector | ✅ World Bank done: 80 records\n",
      "2025-10-17 22:55:50 | INFO     | __main__ | ✅ Done: WorldBank.collect_all in 11.473s\n",
      "2025-10-17 22:55:50 | INFO     | WorldBankCollector | ✅ Saved: world_bank_data.csv (80 rows, 0.01 MB)\n",
      "2025-10-17 22:55:50 | INFO     | __main__ | ✅ world_bank: 80 records\n",
      "Global collection:  12%|████▉                                  | 1/8 [00:11<01:20, 11.49s/collector]2025-10-17 22:55:50 | INFO     | __main__ | ▶️ Starting: imf\n",
      "2025-10-17 22:55:50 | INFO     | __main__ | ⏱️  Start: IMF.collect_all\n",
      "2025-10-17 22:55:50 | INFO     | IMFCollector | 💰 Start IMF collection (5 indicators)\n",
      "\n",
      "IMF:   0%|                                                             | 0/5 [00:00<?, ?indicator/s]\u001B[A\n",
      "IMF:   0%|                                                             | 0/5 [00:00<?, ?indicator/s]\u001B[A2025-10-17 22:55:50 | INFO     | __main__ | ⏱️  Start: IMF.fetch_indicator\n",
      "2025-10-17 22:55:54 | INFO     | __main__ | ✅ Done: IMF.fetch_indicator in 3.618s\n",
      "\n",
      "IMF:  20%|██████████▌                                          | 1/5 [00:04<00:16,  4.13s/indicator]\u001B[A\n",
      "IMF:  20%|██████████▌                                          | 1/5 [00:04<00:16,  4.13s/indicator]\u001B[A2025-10-17 22:55:54 | INFO     | __main__ | ⏱️  Start: IMF.fetch_indicator\n",
      "2025-10-17 22:55:56 | INFO     | __main__ | ✅ Done: IMF.fetch_indicator in 1.299s\n",
      "\n",
      "IMF:  40%|█████████████████████▏                               | 2/5 [00:05<00:08,  2.77s/indicator]\u001B[A\n",
      "IMF:  40%|█████████████████████▏                               | 2/5 [00:05<00:08,  2.77s/indicator]\u001B[A2025-10-17 22:55:56 | INFO     | __main__ | ⏱️  Start: IMF.fetch_indicator\n",
      "2025-10-17 22:55:57 | INFO     | __main__ | ✅ Done: IMF.fetch_indicator in 0.869s\n",
      "\n",
      "IMF:  60%|███████████████████████████████▊                     | 3/5 [00:07<00:04,  2.14s/indicator]\u001B[A\n",
      "IMF:  60%|███████████████████████████████▊                     | 3/5 [00:07<00:04,  2.14s/indicator]\u001B[A2025-10-17 22:55:57 | INFO     | __main__ | ⏱️  Start: IMF.fetch_indicator\n",
      "2025-10-17 22:55:59 | INFO     | __main__ | ✅ Done: IMF.fetch_indicator in 1.318s\n",
      "\n",
      "IMF:  80%|██████████████████████████████████████████▍          | 4/5 [00:09<00:02,  2.01s/indicator]\u001B[A\n",
      "IMF:  80%|██████████████████████████████████████████▍          | 4/5 [00:09<00:02,  2.01s/indicator]\u001B[A2025-10-17 22:55:59 | INFO     | __main__ | ⏱️  Start: IMF.fetch_indicator\n",
      "2025-10-17 22:56:01 | INFO     | __main__ | ✅ Done: IMF.fetch_indicator in 1.212s\n",
      "\n",
      "IMF: 100%|█████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.18s/indicator]\u001B[A\n",
      "2025-10-17 22:56:01 | INFO     | IMFCollector | ✅ IMF done: 0 records\n",
      "2025-10-17 22:56:01 | INFO     | __main__ | ✅ Done: IMF.collect_all in 10.899s\n",
      "2025-10-17 22:56:01 | INFO     | __main__ | ✅ imf: 0 records\n",
      "Global collection:  25%|█████████▊                             | 2/8 [00:22<01:06, 11.15s/collector]2025-10-17 22:56:01 | INFO     | __main__ | ▶️ Starting: who\n",
      "2025-10-17 22:56:01 | INFO     | __main__ | ⏱️  Start: WHO.collect_all\n",
      "2025-10-17 22:56:01 | INFO     | WHOCollector | 🏥 Start WHO collection (4 indicators)\n",
      "\n",
      "WHO:   0%|                                                             | 0/4 [00:00<?, ?indicator/s]\u001B[A\n",
      "WHO:   0%|                                                             | 0/4 [00:00<?, ?indicator/s]\u001B[A2025-10-17 22:56:01 | INFO     | __main__ | ⏱️  Start: WHO.fetch_indicator\n",
      "2025-10-17 22:56:03 | INFO     | __main__ | ✅ Done: WHO.fetch_indicator in 1.709s\n",
      "\n",
      "WHO:  25%|█████████████▎                                       | 1/4 [00:02<00:06,  2.22s/indicator]\u001B[A\n",
      "WHO:  25%|█████████████▎                                       | 1/4 [00:02<00:06,  2.22s/indicator]\u001B[A2025-10-17 22:56:03 | INFO     | __main__ | ⏱️  Start: WHO.fetch_indicator\n",
      "2025-10-17 22:56:04 | INFO     | __main__ | ✅ Done: WHO.fetch_indicator in 1.016s\n",
      "\n",
      "WHO:  50%|██████████████████████████▌                          | 2/4 [00:03<00:03,  1.81s/indicator]\u001B[A\n",
      "WHO:  50%|██████████████████████████▌                          | 2/4 [00:03<00:03,  1.81s/indicator]\u001B[A2025-10-17 22:56:05 | INFO     | __main__ | ⏱️  Start: WHO.fetch_indicator\n",
      "2025-10-17 22:56:06 | INFO     | __main__ | ✅ Done: WHO.fetch_indicator in 0.882s\n",
      "\n",
      "WHO:  75%|███████████████████████████████████████▊             | 3/4 [00:05<00:01,  1.63s/indicator]\u001B[A\n",
      "WHO:  75%|███████████████████████████████████████▊             | 3/4 [00:05<00:01,  1.63s/indicator]\u001B[A2025-10-17 22:56:06 | INFO     | __main__ | ⏱️  Start: WHO.fetch_indicator\n",
      "2025-10-17 22:56:07 | INFO     | __main__ | ✅ Done: WHO.fetch_indicator in 0.956s\n",
      "\n",
      "WHO: 100%|█████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.66s/indicator]\u001B[A\n",
      "2025-10-17 22:56:08 | INFO     | WHOCollector | ✅ WHO done: 0 records\n",
      "2025-10-17 22:56:08 | INFO     | __main__ | ✅ Done: WHO.collect_all in 6.640s\n",
      "2025-10-17 22:56:08 | INFO     | __main__ | ✅ who: 0 records\n",
      "Global collection:  38%|██████████████▋                        | 3/8 [00:29<00:45,  9.09s/collector]2025-10-17 22:56:08 | INFO     | __main__ | ▶️ Starting: undp\n",
      "2025-10-17 22:56:08 | INFO     | __main__ | ⏱️  Start: UNDP.collect_all\n",
      "2025-10-17 22:56:08 | INFO     | UNDPCollector | 🌐 Start UNDP collection\n",
      "2025-10-17 22:56:23 | INFO     | UNDPCollector | ✅ UNDP: 0 records\n",
      "2025-10-17 22:56:23 | INFO     | __main__ | ✅ Done: UNDP.collect_all in 15.229s\n",
      "2025-10-17 22:56:23 | INFO     | __main__ | ✅ undp: 0 records\n",
      "Global collection:  50%|███████████████████▌                   | 4/8 [00:44<00:46, 11.52s/collector]2025-10-17 22:56:23 | INFO     | __main__ | ▶️ Starting: insae\n",
      "2025-10-17 22:56:23 | INFO     | __main__ | ⏱️  Start: INSAE.collect_all\n",
      "2025-10-17 22:56:23 | INFO     | INSAECollector | 🇧🇯 Start INSAE Bénin collection\n",
      "\n",
      "INSAE sources:   0%|                                                      | 0/3 [00:00<?, ?source/s]\u001B[A\n",
      "INSAE sources:   0%|                                                      | 0/3 [00:00<?, ?source/s]\u001B[A2025-10-17 22:56:23 | INFO     | __main__ | ⏱️  Start: INSAE.scrape_source\n",
      "2025-10-17 22:56:32 | WARNING  | INSAECollector | 🔄 Attempt 1/3 - Error on https://www.insae-bj.org/recensement-population.html: Exceeded 30 redirects.\n",
      "2025-10-17 22:56:42 | WARNING  | INSAECollector | 🔄 Attempt 2/3 - Error on https://www.insae-bj.org/recensement-population.html: Exceeded 30 redirects.\n",
      "2025-10-17 22:56:52 | WARNING  | INSAECollector | 🔄 Attempt 3/3 - Error on https://www.insae-bj.org/recensement-population.html: Exceeded 30 redirects.\n",
      "2025-10-17 22:56:52 | ERROR    | INSAECollector | ❌ Failed after 3 attempts: https://www.insae-bj.org/recensement-population.html\n",
      "2025-10-17 22:56:52 | INFO     | __main__ | ✅ Done: INSAE.scrape_source in 29.416s\n",
      "\n",
      "INSAE sources:  33%|███████████████▎                              | 1/3 [00:29<00:58, 29.42s/source]\u001B[A\n",
      "INSAE sources:  33%|███████████████▎                              | 1/3 [00:29<00:58, 29.42s/source]\u001B[A2025-10-17 22:56:52 | INFO     | __main__ | ⏱️  Start: INSAE.scrape_source\n",
      "2025-10-17 22:56:59 | WARNING  | INSAECollector | 🔄 Attempt 1/3 - Error on https://www.insae-bj.org/statistiques-economiques.html: Exceeded 30 redirects.\n",
      "2025-10-17 22:57:10 | WARNING  | INSAECollector | 🔄 Attempt 2/3 - Error on https://www.insae-bj.org/statistiques-economiques.html: Exceeded 30 redirects.\n",
      "2025-10-17 22:57:20 | WARNING  | INSAECollector | 🔄 Attempt 3/3 - Error on https://www.insae-bj.org/statistiques-economiques.html: Exceeded 30 redirects.\n",
      "2025-10-17 22:57:20 | ERROR    | INSAECollector | ❌ Failed after 3 attempts: https://www.insae-bj.org/statistiques-economiques.html\n",
      "2025-10-17 22:57:20 | INFO     | __main__ | ✅ Done: INSAE.scrape_source in 27.606s\n",
      "\n",
      "INSAE sources:  67%|██████████████████████████████▋               | 2/3 [00:57<00:28, 28.36s/source]\u001B[A\n",
      "INSAE sources:  67%|██████████████████████████████▋               | 2/3 [00:57<00:28, 28.36s/source]\u001B[A2025-10-17 22:57:20 | INFO     | __main__ | ⏱️  Start: INSAE.scrape_source\n",
      "2025-10-17 22:57:27 | WARNING  | INSAECollector | 🔄 Attempt 1/3 - Error on https://www.insae-bj.org/emicov.html: Exceeded 30 redirects.\n",
      "2025-10-17 22:57:29 | WARNING  | INSAECollector | 🔄 Attempt 2/3 - Connection error on https://www.insae-bj.org/emicov.html\n",
      "2025-10-17 22:57:40 | WARNING  | INSAECollector | 🔄 Attempt 3/3 - Error on https://www.insae-bj.org/emicov.html: Exceeded 30 redirects.\n",
      "2025-10-17 22:57:40 | ERROR    | INSAECollector | ❌ Failed after 3 attempts: https://www.insae-bj.org/emicov.html\n",
      "2025-10-17 22:57:40 | INFO     | __main__ | ✅ Done: INSAE.scrape_source in 20.228s\n",
      "\n",
      "INSAE sources: 100%|██████████████████████████████████████████████| 3/3 [01:17<00:00, 25.76s/source]\u001B[A\n",
      "2025-10-17 22:57:40 | INFO     | INSAECollector | ✅ INSAE done: 0 records\n",
      "2025-10-17 22:57:40 | INFO     | __main__ | ✅ Done: INSAE.collect_all in 77.288s\n",
      "2025-10-17 22:57:40 | INFO     | __main__ | ✅ insae: 0 records\n",
      "Global collection:  62%|████████████████████████▍              | 5/8 [02:01<01:45, 35.24s/collector]2025-10-17 22:57:40 | INFO     | __main__ | ▶️ Starting: web_scraping\n",
      "2025-10-17 22:57:40 | INFO     | __main__ | ⏱️  Start: WebScraping.collect_all\n",
      "2025-10-17 22:57:40 | INFO     | WebScrapingCollector | 🕷️ Start web scraping\n",
      "\n",
      "Web Scraping:   0%|                                                         | 0/2 [00:00<?, ?site/s]\u001B[A\n",
      "Web Scraping:   0%|                                                         | 0/2 [00:00<?, ?site/s]\u001B[A2025-10-17 22:57:40 | INFO     | __main__ | ⏱️  Start: WebScraping.scrape_tables\n",
      "2025-10-17 22:57:42 | INFO     | WebScrapingCollector | 📋 18 tables found on https://instad.bj/publications/publications-trimestrielles\n",
      "2025-10-17 22:57:42 | INFO     | __main__ | ✅ Done: WebScraping.scrape_tables in 2.156s\n",
      "\n",
      "Web Scraping:  50%|████████████████████████▌                        | 1/2 [00:02<00:02,  2.16s/site]\u001B[A\n",
      "Web Scraping:  50%|████████████████████████▌                        | 1/2 [00:02<00:02,  2.16s/site]\u001B[A2025-10-17 22:57:42 | INFO     | __main__ | ⏱️  Start: WebScraping.scrape_tables\n",
      "2025-10-17 22:57:44 | INFO     | WebScrapingCollector | 📋 3 tables found on https://instad.bj/publications/publications-mensuelles\n",
      "2025-10-17 22:57:44 | INFO     | __main__ | ✅ Done: WebScraping.scrape_tables in 1.268s\n",
      "\n",
      "Web Scraping: 100%|█████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.72s/site]\u001B[A\n",
      "2025-10-17 22:57:44 | INFO     | WebScrapingCollector | ✅ Scraping done: 149 records\n",
      "2025-10-17 22:57:44 | INFO     | __main__ | ✅ Done: WebScraping.collect_all in 3.449s\n",
      "2025-10-17 22:57:44 | INFO     | WebScrapingCollector | ✅ Saved: web_scraping_data.csv (149 rows, 0.03 MB)\n",
      "2025-10-17 22:57:44 | INFO     | __main__ | ✅ web_scraping: 149 records\n",
      "Global collection:  75%|█████████████████████████████▎         | 6/8 [02:05<00:48, 24.43s/collector]2025-10-17 22:57:44 | INFO     | __main__ | ▶️ Starting: geographic\n",
      "2025-10-17 22:57:44 | INFO     | __main__ | ⏱️  Start: Geographic.collect_all\n",
      "2025-10-17 22:57:44 | INFO     | GeographicCollector | 🗺️ Start geographic collection\n",
      "2025-10-17 22:57:44 | INFO     | __main__ | ⏱️  Start: Geographic.execute_query\n",
      "2025-10-17 22:57:49 | INFO     | GeographicCollector | 📍 3480 cities elements collected\n",
      "2025-10-17 22:57:49 | INFO     | __main__ | ✅ Done: Geographic.execute_query in 5.153s\n",
      "\n",
      "Admin boundaries:   0%|                                                    | 0/3 [00:00<?, ?level/s]\u001B[A\n",
      "Admin boundaries:   0%|                                                    | 0/3 [00:00<?, ?level/s]\u001B[A2025-10-17 22:57:49 | INFO     | __main__ | ⏱️  Start: Geographic.execute_query\n",
      "2025-10-17 22:57:51 | INFO     | GeographicCollector | 📍 1 admin_pays elements collected\n",
      "2025-10-17 22:57:51 | INFO     | __main__ | ✅ Done: Geographic.execute_query in 2.441s\n",
      "\n",
      "Admin boundaries:  33%|██████████████▋                             | 1/3 [00:02<00:04,  2.44s/level]\u001B[A\n",
      "Admin boundaries:  33%|██████████████▋                             | 1/3 [00:02<00:04,  2.44s/level]\u001B[A2025-10-17 22:57:51 | INFO     | __main__ | ⏱️  Start: Geographic.execute_query\n",
      "2025-10-17 22:57:56 | WARNING  | GeographicCollector | 🔄 Attempt 1/3 - HTTP N/A on https://overpass-api.de/api/interpreter\n",
      "2025-10-17 22:58:00 | INFO     | GeographicCollector | 📍 0 admin_département elements collected\n",
      "2025-10-17 22:58:00 | INFO     | __main__ | ✅ Done: Geographic.execute_query in 8.401s\n",
      "\n",
      "Admin boundaries:  67%|█████████████████████████████▎              | 2/3 [00:10<00:05,  5.95s/level]\u001B[A\n",
      "Admin boundaries:  67%|█████████████████████████████▎              | 2/3 [00:10<00:05,  5.95s/level]\u001B[A2025-10-17 22:58:00 | INFO     | __main__ | ⏱️  Start: Geographic.execute_query\n",
      "2025-10-17 22:58:02 | INFO     | GeographicCollector | 📍 0 admin_commune elements collected\n",
      "2025-10-17 22:58:02 | INFO     | __main__ | ✅ Done: Geographic.execute_query in 2.374s\n",
      "\n",
      "Admin boundaries: 100%|████████████████████████████████████████████| 3/3 [00:13<00:00,  4.41s/level]\u001B[A\n",
      "2025-10-17 22:58:02 | INFO     | GeographicCollector | ✅ Geographic done: 3481 records\n",
      "2025-10-17 22:58:02 | INFO     | __main__ | ✅ Done: Geographic.collect_all in 18.393s\n",
      "2025-10-17 22:58:02 | INFO     | GeographicCollector | ✅ Saved: geographic_cities.csv (3480 rows, 0.39 MB)\n",
      "2025-10-17 22:58:02 | INFO     | GeographicCollector | ✅ Saved: geographic_admin_pays.csv (1 rows, 0.00 MB)\n",
      "2025-10-17 22:58:02 | INFO     | __main__ | ✅ geographic: 3481 records\n",
      "Global collection:  88%|██████████████████████████████████▏    | 7/8 [02:23<00:22, 22.47s/collector]2025-10-17 22:58:02 | INFO     | __main__ | ▶️ Starting: external\n",
      "2025-10-17 22:58:02 | INFO     | __main__ | ⏱️  Start: External.collect_all\n",
      "2025-10-17 22:58:02 | INFO     | ExternalCollector | 🌐 External collection (1 sources)\n",
      "\n",
      "External sources:   0%|                                                   | 0/1 [00:00<?, ?source/s]\u001B[A\n",
      "External sources:   0%|                                                   | 0/1 [00:00<?, ?source/s]\u001B[A2025-10-17 22:58:02 | INFO     | __main__ | ⏱️  Start: External.download_file\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | ✅ Done: External.download_file in 3.834s\n",
      "2025-10-17 22:58:06 | INFO     | ExternalCollector | ✅ 3 records\n",
      "\n",
      "External sources: 100%|███████████████████████████████████████████| 1/1 [00:03<00:00,  3.84s/source]\u001B[A\n",
      "2025-10-17 22:58:06 | INFO     | ExternalCollector | ✅ External done: 3 records\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | ✅ Done: External.collect_all in 3.844s\n",
      "2025-10-17 22:58:06 | INFO     | ExternalCollector | ✅ Saved: external_data.csv (3 rows, 0.11 MB)\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | ✅ external: 3 records\n",
      "Global collection: 100%|███████████████████████████████████████| 8/8 [02:27<00:00, 18.41s/collector]\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | 🏁 Collection done: 7194 records\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | ✅ Done: Orchestrator.full_collection in 147.343s\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | 🔍 Data quality validation\n",
      "2025-10-17 22:58:06 | WARNING  | __main__ | ⚠️ Issues detected in 4 sources\n",
      "2025-10-17 22:58:06 | WARNING  | __main__ |   - web_scraping: Duplicates: 1\n",
      "2025-10-17 22:58:06 | WARNING  | __main__ |   - web_scraping: Columns >50% nulls: ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim']\n",
      "2025-10-17 22:58:06 | WARNING  | __main__ |   - geographic_cities: Columns >50% nulls: ['population']\n",
      "2025-10-17 22:58:06 | WARNING  | __main__ |   - geographic: Columns >50% nulls: ['population', 'admin_level', 'wikidata']\n",
      "2025-10-17 22:58:06 | WARNING  | __main__ |   - external: Columns >50% nulls: [' science.1', ' culture.1', ' and communication with the UNESCO Institute for Statistics Data Browser.\"/><meta property=\"og:image\" content=\"https://uis-data-browser-frontend-9qoly6dvy-ixt1.vercel.app/Branding/Social Asset_landscape_XXL.png\"/><meta property=\"og:url\" content=\"https://uis-data-browser-frontend-9qoly6dvy-ixt1.vercel.app/index\"/><meta name=\"twitter:card\" content=\"summary_large_image\"/><meta name=\"twitter:title\" content=\"Home - UIS Data Browser\"/><meta name=\"twitter:description\" content=\"Explore comprehensive global data on education', ' science.2', ' culture.2', ' and communication with the UNESCO Institute for Statistics Data Browser.\"/><meta name=\"twitter:image\" content=\"https://uis-data-browser-frontend-9qoly6dvy-ixt1.vercel.app/Branding/Social Asset_landscape_XXL.png\"/><meta name=\"emotion-insertion-point\" content=\"\"/><style data-emotion=\"mui-style-global 0\"></style><style data-emotion=\"mui-style-global p56fei\">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*', '*::before', '*::after{box-sizing:inherit;}strong', 'b{font-weight:700;}body{margin:0;color:rgba(0', ' 0', ' 0.1', ' 0.87);font-weight:400;font-size:18px;line-height:28px;letter-spacing:0;font-family:Noto Sans', \"'-apple-system'\", \"'BlinkMacSystemFont'\", \"'Segoe UI'\", \"'Roboto'\", \"'Helvetica Neue'\", \"'Arial'\", \"'sans-serif'\", \"'Apple Color Emoji'\", \"'Segoe UI Emoji'\", \"'Segoe UI Symbol';background-color:#fff;}@media print{body{background-color:#fff;}}body::backdrop{background-color:#fff;}body{--uis-button-group-tabs-indicator-background:#0069b4;--uis-button-group-tab-color:#0069b4;--uis-button-group-tab-disabled-color:rgba(0\", ' 0.3', ' 0.4', ' 0.38);--uis-button-group-tab-selected-color:#fff;--uis-button-group-tab-border-color:#ebebeb;--mui-divider-color:rgba(0', ' 0.5', ' 0.6', ' 0.12);--mui-slider-mark-color:#0069b4;--mui-slider-thumb-color:#0069b4;--mui-slider-rail-color:#67b0db;--mui-slider-track-color:#0069b4;--mui-outlined-input-color:rgba(0', ' 0.7', ' 0.8', ' 0.87);--mui-outlined-input-notched-outline-border-color:transparent;--mui-outlined-input-hover-notched-outline-border-color:#858585;--mui-outlined-input-background-color:#f5f5f5;--mui-autocomplete-popup-indicator-color:#585858;--mui-autocomplete-clear-indicator-color:#585858;--mui-autocomplete-tag-background-color:#ebebeb;--mui-autocomplete-tag-color:#0069b4;--mui-button-contained-primary-background-color:#0069b4;--mui-button-contained-primary-color:#fff;--mui-button-contained-primary-hover-background-color:#00497c;--mui-button-outlined-primary-border-color:#0069b4;--mui-button-outlined-primary-color:#0069b4;--mui-button-outlined-primary-hover-background-color:#ebf3f9;--mui-button-text-primary-border-color:#0069b4;--mui-button-text-primary-color:#0069b4;--mui-button-text-primary-hover-background-color:#ebf3f9;--mui-chip-filled-color:rgba(0', ' 0.9', ' 0.10', ' 0.87);--mui-chip-filled-background-color:rgba(0', ' 0.11', ' 0.12', ' 0.08);--mui-select-icon-fill:#0069b4;--uis-radio-group-well-background:#fafafa;--uis-radio-group-well-color:rgba(0', ' 0.13', ' 0.14', ' 0.87);--uis-radio-group-well-color-selected:#0069b4;--uis-app-bar-height:64px;}</style><style data-emotion=\"mui-style-global animation-56mw3f\">@-webkit-keyframes animation-56mw3f{0%{opacity:0;-webkit-transform:translateY(-1rem);-moz-transform:translateY(-1rem);-ms-transform:translateY(-1rem);transform:translateY(-1rem);}100%{opacity:1;-webkit-transform:translateY(0);-moz-transform:translateY(0);-ms-transform:translateY(0);transform:translateY(0);}}@keyframes animation-56mw3f{0%{opacity:0;-webkit-transform:translateY(-1rem);-moz-transform:translateY(-1rem);-ms-transform:translateY(-1rem);transform:translateY(-1rem);}100%{opacity:1;-webkit-transform:translateY(0);-moz-transform:translateY(0);-ms-transform:translateY(0);transform:translateY(0);}}</style><style data-emotion=\"mui-style gfhv8f-tinyButton-position 167egg6 1k5uq04-heroContent 1japxzf-symbol qm2s28-TopBar-container 5dfstq-TopBar-bar ygfnsq-TopBar-navFont 1w24irv 149sczi 1egeflc-TopBar-navFont-TopBar-desktopNav 1wd0t83-topbarVariant 70qvj9 ed2cz-TopBar-menuBtn q7mezt xt5v3l k341i1 f024n4-cartTrigger d6ketg 8c556v-hero ij0u24 vrbv4l w9wc3r 1fq0z56 6r2fzw 1t98mfd gu0jcc-cta 1lv5skk 867tzq-wave g6ot07-smallerLine 15p1w1i-logoContainer l0wajo-root 11z7gjw-contentPageSections wzh0ll t4aypk-Keyfact-masonry 1a30ymk-Keyfact-targetIcon hazch5-Keyfact-card-keyfact-Keyfact-tall 8naohf 173mjkp-Keyfact-targetChip 4y436t 1flbsx1-Keyfact-title m9650t-Keyfact-subtitle 1ukbohm 1te1yf2-Keyfact-body i9gxme fgk73c-button-Keyfact-ctaButton 5yqlck 58tzh1-contentPageSections x7c13k-DataInsightCarousel-root 1p5a8ak-DataInsightCarousel-arrowContainer-DataInsightCarousel-arrowLeft 1ciia0c-DataInsightCarousel-arrowContainer-DataInsightCarousel-arrowRight tb4fyx-DataInsightCarousel-iconButton 1yqluvs-DataInsightCarousel-content 10aqcja-DataInsight-cardWrapper 7sxby4-DataInsight-card pn485x-ThemeStatistics-illustration xqliwt-ThemeStatistics-root 4ex6rx 1cxnjrt o3djwr 7c8wqm 1ka0xgm-FeatureCarousel-texts 9whjg2-FeatureCarousel-images 16kaw1y-FeatureCarousel-featureImage t8xy5e-FeatureCarousel-featureItem-FeatureCarousel-inactive 5nla4c-FeatureCarousel-container ebkpew n69y0b jd03v9 79elbk 1hz5k7v b1gm9m-root t0051x 18yqq8n 1ew9uej 1sh75vq 1ri9ct8 1npii3n 9wy2gx-DataInsightCarousel-content 1d6k93d-DataInsightCarousel-root 13yzri3 1s5a2t9 16hnoe6 1wbsfxw\">.mui-style-gfhv8f-tinyButton-position{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;font-family:Noto Sans', \"'-apple-system'.1\", \"'BlinkMacSystemFont'.1\", \"'Segoe UI'.1\", \"'Roboto'.1\", \"'Helvetica Neue'.1\", \"'Arial'.1\", \"'sans-serif'.1\", \"'Apple Color Emoji'.1\", \"'Segoe UI Emoji'.1\", \"'Segoe UI Symbol';font-weight:500;font-size:0.875rem;line-height:1.75;text-transform:uppercase;min-width:64px;padding:6px 16px;border:0;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4\", ' 0.15', ' 0.2', ' 1) 0ms', 'box-shadow 250ms cubic-bezier(0.4', ' 0.16', ' 0.2.1', ' 1) 0ms.1', 'border-color 250ms cubic-bezier(0.4', ' 0.17', ' 0.2.2', ' 1) 0ms.2', 'color 250ms cubic-bezier(0.4', ' 0.18', ' 0.2.3', ' 1) 0ms;transition:background-color 250ms cubic-bezier(0.4', ' 0.19', ' 0.2.4', ' 1) 0ms.3', 'box-shadow 250ms cubic-bezier(0.4.1', ' 0.20', ' 0.2.5', ' 1) 0ms.4', 'border-color 250ms cubic-bezier(0.4.1', ' 0.21', ' 0.2.6', ' 1) 0ms.5', 'color 250ms cubic-bezier(0.4.1', ' 0.22', ' 0.2.7', ' 1) 0ms;color:var(--variant-containedColor);background-color:var(--variant-containedBg);box-shadow:0px 1px 5px #00000014', '0px 1px 2px #0000000f;--variant-textColor:#0069b4;--variant-outlinedColor:#0069b4;--variant-outlinedBorder:rgba(0', ' 105', ' 180', ' 0.5);--variant-containedColor:#fff;--variant-containedBg:#0069b4;padding:4px 10px;font-size:0.8125rem;font-style:normal;font-weight:400;text-transform:none;line-height:24px;border-radius:0px;box-shadow:none;background-color:var(--mui-button-contained-primary-background-color);color:var(--mui-button-contained-primary-color);font-size:14px;min-height:32px;padding:0 16px;position:fixed;bottom:0;right:0;margin:0px 16px;border-top-left-radius:8px;border-top-right-radius:8px;box-shadow:0px 7px 8px #00000029', '0px 5px 22px #00000014', '0px 12px 17px #0000001a;background-color:white;color:#0069b4;bottom:0;right:0;position:fixed;z-index:1000;}.mui-style-gfhv8f-tinyButton-position::-moz-focus-inner{border-style:none;}.mui-style-gfhv8f-tinyButton-position.Mui-disabled{pointer-events:none;cursor:default;}@media print{.mui-style-gfhv8f-tinyButton-position{-webkit-print-color-adjust:exact;color-adjust:exact;}}.mui-style-gfhv8f-tinyButton-position:hover{-webkit-text-decoration:none;text-decoration:none;}.mui-style-gfhv8f-tinyButton-position.Mui-disabled{color:rgba(0', ' 0.23', ' 0.24', ' 0.26);}.mui-style-gfhv8f-tinyButton-position:hover{box-shadow:0px 5px 20px #00000014', '0px 2px 6px #0000000d;}@media (hover: none){.mui-style-gfhv8f-tinyButton-position:hover{box-shadow:0px 1px 5px #00000014', '0px 1px 2px #0000000f;}}.mui-style-gfhv8f-tinyButton-position:active{box-shadow:none;}.mui-style-gfhv8f-tinyButton-position.Mui-focusVisible{box-shadow:0px 10px 20px #0000000d', '1px 10px 70px #00000021;}.mui-style-gfhv8f-tinyButton-position.Mui-disabled{color:rgba(0', ' 0.25', ' 0.26', ' 0.26);box-shadow:0px 0px 0px #00000000;background-color:rgba(0', ' 0.27', ' 0.28', ' 0.12);}@media (hover: hover){.mui-style-gfhv8f-tinyButton-position:hover{--variant-containedBg:#00497c;--variant-textBg:rgba(0', ' 105.1', ' 180.1', ' 0.04);--variant-outlinedBorder:#0069b4;--variant-outlinedBg:rgba(0', ' 105.2', ' 180.2', ' 0.04);}}.mui-style-gfhv8f-tinyButton-position:hover{box-shadow:0px 1px 5px #00000014', '0px 1px 2px #0000000f;}.mui-style-gfhv8f-tinyButton-position:hover{background-color:var(--mui-button-contained-primary-hover-background-color);}.mui-style-gfhv8f-tinyButton-position:hover{background-color:white;box-shadow:0px 7px 8px #00000029', '0px 5px 22px #00000014.1', '0px 12px 17px #0000001a;}.mui-style-167egg6{margin:0;font-weight:700;font-size:12px;line-height:18px;letter-spacing:0;}.mui-style-1k5uq04-heroContent{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:32px;}@media (max-width:899.95px){.mui-style-1k5uq04-heroContent{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}}.mui-style-1japxzf-symbol{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-align-self:flex-start;-ms-flex-item-align:flex-start;align-self:flex-start;}.mui-style-qm2s28-TopBar-container{position:fixed;left:0;right:0;top:0;margin:auto;z-index:1100;-webkit-transition:box-shadow 0.5s ease;transition:box-shadow 0.5s ease;}.mui-style-qm2s28-TopBar-container:after{content:\" \";display:block;height:20px;position:absolute;top:0;left:0;right:0;margin:auto;}.mui-style-5dfstq-TopBar-bar{background-color:#fff;color:rgba(0', ' 0.29', ' 0.30', ' 0.87);-webkit-transition:box-shadow 300ms cubic-bezier(0.4', ' 0.31', ' 0.2.8', ' 1) 0ms;transition:box-shadow 300ms cubic-bezier(0.4', ' 0.32', ' 0.2.9', ' 1) 0ms;box-shadow:var(--Paper-shadow);background-image:var(--Paper-overlay);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:fixed;z-index:1100;top:0;left:auto;right:0;--AppBar-background:#0069b4;--AppBar-color:#fff;background-color:var(--AppBar-background);color:var(--AppBar-color);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;min-height:var(--app-bar-height);-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;box-shadow:none;background-color:#23305f;position:static;}@media print{.mui-style-5dfstq-TopBar-bar{position:absolute;}}.mui-style-ygfnsq-TopBar-navFont{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;padding-left:16px;padding-right:16px;font-weight:600;font-family:Noto Sans', \"'-apple-system'.2\", \"'BlinkMacSystemFont'.2\", \"'Segoe UI'.2\", \"'Roboto'.2\", \"'Helvetica Neue'.2\", \"'Arial'.2\", \"'sans-serif'.2\", \"'Apple Color Emoji'.2\", \"'Segoe UI Emoji'.2\", \"'Segoe UI Symbol';text-transform:uppercase;font-size:18px;line-height:24px;}.mui-style-1w24irv{cursor:pointer;line-height:1;}.mui-style-149sczi{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;gap:16px;}.mui-style-1egeflc-TopBar-navFont-TopBar-desktopNav{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;gap:16px;font-weight:600;font-family:Noto Sans\", \"'-apple-system'.3\", \"'BlinkMacSystemFont'.3\", \"'Segoe UI'.3\", \"'Roboto'.3\", \"'Helvetica Neue'.3\", \"'Arial'.3\", \"'sans-serif'.3\", \"'Apple Color Emoji'.3\", \"'Segoe UI Emoji'.3\", \"'Segoe UI Symbol';text-transform:uppercase;font-size:18px;line-height:24px;}@media (max-width:1199.95px){.mui-style-1egeflc-TopBar-navFont-TopBar-desktopNav{display:none;}}.mui-style-1wd0t83-topbarVariant{margin:0;font:inherit;line-height:inherit;letter-spacing:inherit;color:#0069b4;-webkit-text-decoration:none;text-decoration:none;color:#fff;opacity:0.55;typography:overline;min-height:64px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;padding:0 0.5rem;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:opacity 0.15s ease;transition:opacity 0.15s ease;}.mui-style-1wd0t83-topbarVariant:hover{opacity:1;}.mui-style-70qvj9{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.mui-style-ed2cz-TopBar-menuBtn{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;color:rgba(0\", ' 0.33', ' 0.34', ' 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4', ' 0.35', ' 0.2.10', ' 1) 0ms;transition:background-color 150ms cubic-bezier(0.4', ' 0.36', ' 0.2.11', ' 1) 0ms;--IconButton-hoverBg:rgba(0', ' 0.37', ' 0.38', ' 0.04);display:none;color:white;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;}.mui-style-ed2cz-TopBar-menuBtn::-moz-focus-inner{border-style:none;}.mui-style-ed2cz-TopBar-menuBtn.Mui-disabled{pointer-events:none;cursor:default;}@media print{.mui-style-ed2cz-TopBar-menuBtn{-webkit-print-color-adjust:exact;color-adjust:exact;}}.mui-style-ed2cz-TopBar-menuBtn:hover{background-color:var(--IconButton-hoverBg);}@media (hover: none){.mui-style-ed2cz-TopBar-menuBtn:hover{background-color:transparent;}}.mui-style-ed2cz-TopBar-menuBtn.Mui-disabled{background-color:transparent;color:rgba(0', ' 0.39', ' 0.40', ' 0.26);}@media (max-width:1199.95px){.mui-style-ed2cz-TopBar-menuBtn{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}}.mui-style-q7mezt{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4', ' 0.41', ' 0.2.12', ' 1) 0ms;transition:fill 200ms cubic-bezier(0.4', ' 0.42', ' 0.2.13', ' 1) 0ms;fill:currentColor;font-size:1.5rem;}.mui-style-xt5v3l{margin:0;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;border-width:0;border-style:solid;border-color:rgba(0', ' 0.43', ' 0.44', ' 0.12);border-bottom-width:thin;height:100%;border-bottom-width:0;border-right-width:thin;border-color:var(--mui-divider-color);margin-right:16px;border-left:1px solid;border-left-color:rgba(255', ' 255', ' 255.1', ' 0.5);height:2rem;}.mui-style-k341i1{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;position:relative;}.mui-style-f024n4-cartTrigger{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;color:rgba(0', ' 0.45', ' 0.46', ' 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4.1', ' 0.47', ' 0.2.14', ' 1) 0ms;transition:background-color 150ms cubic-bezier(0.4.1', ' 0.48', ' 0.2.15', ' 1) 0ms;--IconButton-hoverBg:rgba(0.1', ' 0.49', ' 0.50', ' 0.04);padding:12px;color:#0069b4;-webkit-transition:background 0.25s ease;transition:background 0.25s ease;}.mui-style-f024n4-cartTrigger::-moz-focus-inner{border-style:none;}.mui-style-f024n4-cartTrigger.Mui-disabled{pointer-events:none;cursor:default;}@media print{.mui-style-f024n4-cartTrigger{-webkit-print-color-adjust:exact;color-adjust:exact;}}.mui-style-f024n4-cartTrigger:hover{background-color:var(--IconButton-hoverBg);}@media (hover: none){.mui-style-f024n4-cartTrigger:hover{background-color:transparent;}}.mui-style-f024n4-cartTrigger.Mui-disabled{background-color:transparent;color:rgba(0', ' 0.51', ' 0.52', ' 0.26);}.mui-style-f024n4-cartTrigger:hover{background-color:white;}.mui-style-d6ketg{display:grid;min-height:100vh;grid-template-rows:1fr min-content;padding-top:0px;background-color:#f5f5f5;}.mui-style-8c556v-hero{padding-top:169px;background-color:#23305f;color:white;}.mui-style-ij0u24{margin-left:16px;margin-right:16px;margin-bottom:80px;}.mui-style-vrbv4l{max-width:1156px;}@media (min-width:0px){.mui-style-vrbv4l{margin-left:0.5rem;margin-right:0.5rem;}}@media (min-width:600px){.mui-style-vrbv4l{margin-left:0.5rem;margin-right:0.5rem;}}@media (min-width:900px){.mui-style-vrbv4l{margin-left:auto;margin-right:auto;}}.mui-style-w9wc3r{display:grid;gap:0px;}@media (min-width:0px){.mui-style-w9wc3r{grid-template-columns:auto;grid-template-rows:auto auto;}}@media (min-width:600px){.mui-style-w9wc3r{grid-template-columns:auto 1fr;grid-template-rows:auto;}}.mui-style-1fq0z56{margin:0;font-weight:500;font-size:88px;line-height:88px;letter-spacing:0;margin-bottom:56px;display:block;max-width:802px;}.mui-style-6r2fzw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;gap:32px;}.mui-style-1t98mfd{margin:0;font-weight:400;font-size:18px;line-height:28px;letter-spacing:0;font-family:Noto Sans', \"'-apple-system'.4\", \"'BlinkMacSystemFont'.4\", \"'Segoe UI'.4\", \"'Roboto'.4\", \"'Helvetica Neue'.4\", \"'Arial'.4\", \"'sans-serif'.4\", \"'Apple Color Emoji'.4\", \"'Segoe UI Emoji'.4\", \"'Segoe UI Symbol';font-size:24px;line-height:32px;}.mui-style-gu0jcc-cta{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;font-family:Noto Sans\", \"'-apple-system'.5\", \"'BlinkMacSystemFont'.5\", \"'Segoe UI'.5\", \"'Roboto'.5\", \"'Helvetica Neue'.5\", \"'Arial'.5\", \"'sans-serif'.5\", \"'Apple Color Emoji'.5\", \"'Segoe UI Emoji'.5\", \"'Segoe UI Symbol';font-weight:500;font-size:0.875rem;line-height:1.75;text-transform:uppercase;min-width:64px;padding:6px 16px;border:0;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4.1\", ' 0.53', ' 0.2.16', ' 1) 0ms.6', 'box-shadow 250ms cubic-bezier(0.4.2', ' 0.54', ' 0.2.17', ' 1) 0ms.7', 'border-color 250ms cubic-bezier(0.4.2', ' 0.55', ' 0.2.18', ' 1) 0ms.8', 'color 250ms cubic-bezier(0.4.2', ' 0.56', ' 0.2.19', ' 1) 0ms;transition:background-color 250ms cubic-bezier(0.4.1', ' 0.57', ' 0.2.20', ' 1) 0ms.9', 'box-shadow 250ms cubic-bezier(0.4.3', ' 0.58', ' 0.2.21', ' 1) 0ms.10', 'border-color 250ms cubic-bezier(0.4.3', ' 0.59', ' 0.2.22', ' 1) 0ms.11', 'color 250ms cubic-bezier(0.4.3', ' 0.60', ' 0.2.23', ' 1) 0ms;padding:6px 8px;color:var(--variant-textColor);background-color:var(--variant-textBg);--variant-textColor:#0069b4;--variant-outlinedColor:#0069b4;--variant-outlinedBorder:rgba(0', ' 105.3', ' 180.3', ' 0.5);--variant-containedColor:#fff;--variant-containedBg:#0069b4;font-style:normal;font-weight:400;text-transform:none;line-height:24px;border-radius:0px;color:var(--mui-button-text-primary-color);font-size:16px;min-height:48px;padding:0 24px;font-weight:400;font-size:16px;line-height:24px;letter-spacing:0;font-family:Noto Sans', \"'-apple-system'.6\", \"'BlinkMacSystemFont'.6\", \"'Segoe UI'.6\", \"'Roboto'.6\", \"'Helvetica Neue'.6\", \"'Arial'.6\", \"'sans-serif'.6\", \"'Apple Color Emoji'.6\", \"'Segoe UI Emoji'.6\", \"'Segoe UI Symbol';width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;background-color:#0069b4;padding:16px;color:white;}.mui-style-gu0jcc-cta::-moz-focus-inner{border-style:none;}.mui-style-gu0jcc-cta.Mui-disabled{pointer-events:none;cursor:default;}@media print{.mui-style-gu0jcc-cta{-webkit-print-color-adjust:exact;color-adjust:exact;}}.mui-style-gu0jcc-cta:hover{-webkit-text-decoration:none;text-decoration:none;}.mui-style-gu0jcc-cta.Mui-disabled{color:rgba(0\", ' 0.61', ' 0.62', ' 0.26);}@media (hover: hover){.mui-style-gu0jcc-cta:hover{--variant-containedBg:#00497c;--variant-textBg:rgba(0', ' 105.4', ' 180.4', ' 0.04);--variant-outlinedBorder:#0069b4;--variant-outlinedBg:rgba(0.1', ' 105.5', ' 180.5', ' 0.04);}}.mui-style-gu0jcc-cta:hover{background-color:var(--mui-button-text-primary-hover-background-color);}.mui-style-gu0jcc-cta:hover{background-color:#00497c;}.mui-style-1lv5skk{-webkit-align-items:column;-webkit-box-align:column;-ms-flex-align:column;align-items:column;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:end;-ms-flex-pack:end;-webkit-justify-content:flex-end;justify-content:flex-end;}@media (min-width:0px){.mui-style-1lv5skk{display:none;}}@media (min-width:600px){.mui-style-1lv5skk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}.mui-style-867tzq-wave{-webkit-transform:scaleY(-1);-moz-transform:scaleY(-1);-ms-transform:scaleY(-1);transform:scaleY(-1);-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;right:0;top:0;position:absolute;}.mui-style-g6ot07-smallerLine{height:22px;z-index:1;background:var(--background);position:absolute;bottom:0;left:0;right:0;}.mui-style-15p1w1i-logoContainer{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:var(--background);padding-right:32px;padding-left:16px;z-index:1;}.mui-style-l0wajo-root{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;-webkit-justify-content:flex-end;justify-content:flex-end;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;width:100%;z-index:1;--background:#2684c2;height:80px;margin-top:-3.5rem;}.mui-style-11z7gjw-contentPageSections{background-color:#fff;padding-top:80px;padding-bottom:100px;padding:80px 24px 100px;}.mui-style-wzh0ll{margin:0;font-weight:700;font-size:32px;line-height:64px;letter-spacing:0;font-family:Noto Sans', \"'-apple-system'.7\", \"'BlinkMacSystemFont'.7\", \"'Segoe UI'.7\", \"'Roboto'.7\", \"'Helvetica Neue'.7\", \"'Arial'.7\", \"'sans-serif'.7\", \"'Apple Color Emoji'.7\", \"'Segoe UI Emoji'.7\", \"'Segoe UI Symbol';margin-bottom:32px;color:#23305f;}.mui-style-t4aypk-Keyfact-masonry{display:grid;gap:12px;grid-template-columns:repeat(var(--cols)\", ' minmax(0', ' 1fr));}.mui-style-1a30ymk-Keyfact-targetIcon{color:#0069b4;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall{background-color:#fff;color:rgba(0', ' 0.63', ' 0.64', ' 0.87);-webkit-transition:box-shadow 300ms cubic-bezier(0.4.1', ' 0.65', ' 0.2.24', ' 1) 0ms;transition:box-shadow 300ms cubic-bezier(0.4.1', ' 0.66', ' 0.2.25', ' 1) 0ms;box-shadow:var(--Paper-shadow);background-image:var(--Paper-overlay);overflow:hidden;border-color:#ebebeb;padding:24px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;overflow:hidden;-webkit-transition:-webkit-transform 0.3s ease;transition:transform 0.3s ease;box-shadow:none;-webkit-animation:animation-56mw3f 0.375s ease;animation:animation-56mw3f 0.375s ease;-webkit-animation-fill-mode:both;animation-fill-mode:both;grid-row:span 2;background:#FAFAFA;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:hover{-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01);justify-self:flex-end;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(2n + 1){background:#FAFAFA;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall .mui-style-22-Keyfact-title-ref', '.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall .mui-style-22-Keyfact-subtitle-ref{color:#23305f;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(0){-webkit-animation-delay:0s;animation-delay:0s;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(1){-webkit-animation-delay:0.1s;animation-delay:0.1s;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(2){-webkit-animation-delay:0.2s;animation-delay:0.2s;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(3){-webkit-animation-delay:0.30000000000000004s;animation-delay:0.30000000000000004s;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(4){-webkit-animation-delay:0.4s;animation-delay:0.4s;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(5){-webkit-animation-delay:0.5s;animation-delay:0.5s;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(6){-webkit-animation-delay:0.6000000000000001s;animation-delay:0.6000000000000001s;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(7){-webkit-animation-delay:0.7000000000000001s;animation-delay:0.7000000000000001s;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(8){-webkit-animation-delay:0.8s;animation-delay:0.8s;}.mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall:nth-of-type(9){-webkit-animation-delay:0.9s;animation-delay:0.9s;}.mui-style-8naohf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;gap:10px;margin-bottom:14px;}.mui-style-173mjkp-Keyfact-targetChip{max-width:100%;font-family:Noto Sans', \"'-apple-system'.8\", \"'BlinkMacSystemFont'.8\", \"'Segoe UI'.8\", \"'Roboto'.8\", \"'Helvetica Neue'.8\", \"'Arial'.8\", \"'sans-serif'.8\", \"'Apple Color Emoji'.8\", \"'Segoe UI Emoji'.8\", \"'Segoe UI Symbol';font-size:0.8125rem;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;height:32px;color:rgba(0\", ' 0.67', ' 0.68', ' 0.87);background-color:rgba(0', ' 0.69', ' 0.70', ' 0.08);border-radius:16px;white-space:nowrap;-webkit-transition:background-color 300ms cubic-bezier(0.4', ' 0.71', ' 0.2.26', ' 1) 0ms.12', 'box-shadow 300ms cubic-bezier(0.4', ' 0.72', ' 0.2.27', ' 1) 0ms;transition:background-color 300ms cubic-bezier(0.4', ' 0.73', ' 0.2.28', ' 1) 0ms.13', 'box-shadow 300ms cubic-bezier(0.4.1', ' 0.74', ' 0.2.29', ' 1) 0ms;cursor:unset;outline:0;-webkit-text-decoration:none;text-decoration:none;border:0;padding:0;vertical-align:middle;box-sizing:border-box;height:24px;border-radius:0;border-radius:20px;color:#333333;cursor:pointer;}.mui-style-173mjkp-Keyfact-targetChip.Mui-disabled{opacity:0.38;pointer-events:none;}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-avatar{margin-left:5px;margin-right:-6px;width:24px;height:24px;color:#585858;font-size:0.75rem;}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-avatarColorPrimary{color:#fff;background-color:#00497c;}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-avatarColorSecondary{color:#fff;background-color:#7b1fa2;}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-avatarSmall{margin-left:4px;margin-right:-4px;width:18px;height:18px;font-size:0.625rem;}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-icon{margin-left:5px;margin-right:-6px;}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-deleteIcon{-webkit-tap-highlight-color:transparent;color:rgba(0', ' 0.75', ' 0.76', ' 0.26);font-size:22px;cursor:pointer;margin:0 5px 0 -6px;}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-deleteIcon:hover{color:rgba(0', ' 0.77', ' 0.78', ' 0.4);}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-icon{font-size:18px;margin-left:4px;margin-right:-4px;}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-deleteIcon{font-size:16px;margin-right:4px;margin-left:-4px;}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-icon{color:#585858;}.mui-style-173mjkp-Keyfact-targetChip .MuiChip-label{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;gap:0.25rem;}.mui-style-173mjkp-Keyfact-targetChip:hover{background-color:#dddddd;}.mui-style-4y436t{overflow:hidden;text-overflow:ellipsis;padding-left:12px;padding-right:12px;white-space:nowrap;padding-left:8px;padding-right:8px;}.mui-style-1flbsx1-Keyfact-title{margin:0;font-weight:700;font-size:32px;line-height:64px;letter-spacing:0;font-family:Noto Sans', \"'-apple-system'.9\", \"'BlinkMacSystemFont'.9\", \"'Segoe UI'.9\", \"'Roboto'.9\", \"'Helvetica Neue'.9\", \"'Arial'.9\", \"'sans-serif'.9\", \"'Apple Color Emoji'.9\", \"'Segoe UI Emoji'.9\", \"'Segoe UI Symbol';margin-bottom:8px;line-height:1.25;-webkit-flex-basis:max-content;-ms-flex-preferred-size:max-content;flex-basis:max-content;}.mui-style-m9650t-Keyfact-subtitle{margin:0;font-weight:700;font-size:16px;line-height:24px;letter-spacing:0;font-family:Noto Sans\", \"'-apple-system'.10\", \"'BlinkMacSystemFont'.10\", \"'Segoe UI'.10\", \"'Roboto'.10\", \"'Helvetica Neue'.10\", \"'Arial'.10\", \"'sans-serif'.10\", \"'Apple Color Emoji'.10\", \"'Segoe UI Emoji'.10\", \"'Segoe UI Symbol';line-height:1.5;-webkit-flex-basis:max-content;-ms-flex-preferred-size:max-content;flex-basis:max-content;}.mui-style-1ukbohm{margin:0;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;border-width:0;border-style:solid;border-color:rgba(0\", ' 0.79', ' 0.80', ' 0.12);border-bottom-width:thin;border-color:var(--mui-divider-color);margin-top:8px;margin-bottom:8px;-webkit-align-self:stretch;-ms-flex-item-align:stretch;align-self:stretch;}.mui-style-1te1yf2-Keyfact-body{margin:0;font-weight:400;font-size:12px;line-height:18px;letter-spacing:0;color:rgba(0', ' 0.81', ' 0.82', ' 0.6);display:block;-webkit-flex-basis:max-content;-ms-flex-preferred-size:max-content;flex-basis:max-content;overflow:hidden;}.mui-style-1te1yf2-Keyfact-body p:first-of-type{margin-top:0;}.mui-style-1te1yf2-Keyfact-body table{width:100%;}.mui-style-1te1yf2-Keyfact-body th{text-align:left;}.mui-style-i9gxme{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}.mui-style-fgk73c-button-Keyfact-ctaButton{margin:0;font:inherit;line-height:inherit;letter-spacing:inherit;color:#0069b4;-webkit-text-decoration:underline;text-decoration:underline;text-decoration-color:var(--Link-underlineColor);--Link-underlineColor:rgba(0', ' 105.6', ' 180.6', ' 0.4);display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;font-family:Noto Sans', \"'-apple-system'.11\", \"'BlinkMacSystemFont'.11\", \"'Segoe UI'.11\", \"'Roboto'.11\", \"'Helvetica Neue'.11\", \"'Arial'.11\", \"'sans-serif'.11\", \"'Apple Color Emoji'.11\", \"'Segoe UI Emoji'.11\", \"'Segoe UI Symbol';font-weight:500;font-size:0.875rem;line-height:1.75;text-transform:uppercase;min-width:64px;padding:6px 16px;border:0;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4.2\", ' 0.83', ' 0.2.30', ' 1) 0ms.14', 'box-shadow 250ms cubic-bezier(0.4.4', ' 0.84', ' 0.2.31', ' 1) 0ms.15', 'border-color 250ms cubic-bezier(0.4.4', ' 0.85', ' 0.2.32', ' 1) 0ms.16', 'color 250ms cubic-bezier(0.4.4', ' 0.86', ' 0.2.33', ' 1) 0ms;transition:background-color 250ms cubic-bezier(0.4.2', ' 0.87', ' 0.2.34', ' 1) 0ms.17', 'box-shadow 250ms cubic-bezier(0.4.5', ' 0.88', ' 0.2.35', ' 1) 0ms.18', 'border-color 250ms cubic-bezier(0.4.5', ' 0.89', ' 0.2.36', ' 1) 0ms.19', 'color 250ms cubic-bezier(0.4.5', ' 0.90', ' 0.2.37', ' 1) 0ms;padding:6px 8px;color:var(--variant-textColor);background-color:var(--variant-textBg);--variant-textColor:#0069b4;--variant-outlinedColor:#0069b4;--variant-outlinedBorder:rgba(0.1', ' 105.7', ' 180.7', ' 0.5);--variant-containedColor:#fff;--variant-containedBg:#0069b4;padding:4px 5px;font-size:0.8125rem;font-style:normal;font-weight:400;text-transform:none;line-height:24px;border-radius:0px;color:var(--mui-button-text-primary-color);font-size:14px;min-height:32px;padding:0 16px;margin-left:4px;padding:0;background-image:linear-gradient(to bottom', ' #0069b4 0px', ' #0069b4 1.5px ', ' transparent 1.5px', ' transparent 100%);background-position-y:calc(2rem - 2px);background-repeat:no-repeat;-webkit-background-size:0% 100%;background-size:0% 100%;-webkit-transition:-webkit-transform 0.5s ease', 'border-color 0.3s ease', 'background-size 0.3s ease;transition:transform 0.5s ease', 'border-color 0.3s ease.1', 'background-size 0.3s ease;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-self:flex-start;-ms-flex-item-align:flex-start;align-self:flex-start;margin-top:16px;margin-left:0px;}.mui-style-fgk73c-button-Keyfact-ctaButton:hover{text-decoration-color:inherit;}.mui-style-fgk73c-button-Keyfact-ctaButton::-moz-focus-inner{border-style:none;}.mui-style-fgk73c-button-Keyfact-ctaButton.Mui-disabled{pointer-events:none;cursor:default;}@media print{.mui-style-fgk73c-button-Keyfact-ctaButton{-webkit-print-color-adjust:exact;color-adjust:exact;}}.mui-style-fgk73c-button-Keyfact-ctaButton:hover{-webkit-text-decoration:none;text-decoration:none;}.mui-style-fgk73c-button-Keyfact-ctaButton.Mui-disabled{color:rgba(0', ' 0.91', ' 0.92', ' 0.26);}@media (hover: hover){.mui-style-fgk73c-button-Keyfact-ctaButton:hover{--variant-containedBg:#00497c;--variant-textBg:rgba(0', ' 105.8', ' 180.8', ' 0.04);--variant-outlinedBorder:#0069b4;--variant-outlinedBg:rgba(0.2', ' 105.9', ' 180.9', ' 0.04);}}.mui-style-fgk73c-button-Keyfact-ctaButton:hover{background-color:var(--mui-button-text-primary-hover-background-color);}.mui-style-fgk73c-button-Keyfact-ctaButton:hover{background-color:transparent;-webkit-background-size:100% 100%;background-size:100% 100%;}.mui-style-5yqlck{display:inherit;margin-right:-4px;margin-left:8px;margin-right:-2px;}.mui-style-5yqlck>*:nth-of-type(1){font-size:18px;}.mui-style-58tzh1-contentPageSections{background-color:#fafafa;padding-top:80px;padding-bottom:100px;padding:80px 24px 100px;}.mui-style-x7c13k-DataInsightCarousel-root{position:relative;display:grid;grid-template-columns:min-content 1fr min-content;grid-template-areas:\"last content next\";}@media (max-width:899.95px){.mui-style-x7c13k-DataInsightCarousel-root{grid-template-columns:min-content 1fr 1fr min-content;grid-template-areas:\"content content content content\" \"last last next next\";row-gap:16px;}}@media (min-width: 1232px){.mui-style-x7c13k-DataInsightCarousel-root{margin:0 -38px;}}.mui-style-1p5a8ak-DataInsightCarousel-arrowContainer-DataInsightCarousel-arrowLeft{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;left:-4rem;grid-area:last;padding-right:12px;}@media (max-width:899.95px){.mui-style-1p5a8ak-DataInsightCarousel-arrowContainer-DataInsightCarousel-arrowLeft{place-self:flex-end;}}.mui-style-1ciia0c-DataInsightCarousel-arrowContainer-DataInsightCarousel-arrowRight{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;right:-4rem;grid-area:next;padding-left:8px;}.mui-style-tb4fyx-DataInsightCarousel-iconButton{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;color:rgba(0', ' 0.93', ' 0.94', ' 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4.2', ' 0.95', ' 0.2.38', ' 1) 0ms;transition:background-color 150ms cubic-bezier(0.4.2', ' 0.96', ' 0.2.39', ' 1) 0ms;--IconButton-hoverBg:rgba(0.2', ' 0.97', ' 0.98', ' 0.04);color:#0069b4;--IconButton-hoverBg:rgba(0', ' 105.10', ' 180.10', ' 0.04);padding:5px;font-size:1.125rem;background:#0069b4;color:white;}.mui-style-tb4fyx-DataInsightCarousel-iconButton::-moz-focus-inner{border-style:none;}.mui-style-tb4fyx-DataInsightCarousel-iconButton.Mui-disabled{pointer-events:none;cursor:default;}@media print{.mui-style-tb4fyx-DataInsightCarousel-iconButton{-webkit-print-color-adjust:exact;color-adjust:exact;}}.mui-style-tb4fyx-DataInsightCarousel-iconButton:hover{background-color:var(--IconButton-hoverBg);}@media (hover: none){.mui-style-tb4fyx-DataInsightCarousel-iconButton:hover{background-color:transparent;}}.mui-style-tb4fyx-DataInsightCarousel-iconButton.Mui-disabled{background-color:transparent;color:rgba(0', ' 0.99', ' 0.100', ' 0.26);}.mui-style-tb4fyx-DataInsightCarousel-iconButton:hover{background:#2684c2;}.mui-style-1yqluvs-DataInsightCarousel-content{display:grid;grid-template-columns:repeat(3', ' minmax(0.1', ' 1fr));gap:2rem;grid-area:content;}.mui-style-10aqcja-DataInsight-cardWrapper{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;gap:8px;cursor:pointer;}.mui-style-10aqcja-DataInsight-cardWrapper:hover .mui-style-28-DataInsight-card-ref{border-color:rgba(0', ' 0.101', ' 0.102', ' 0.12);box-shadow:0px 5px 20px #00000014', '0px 2px 6px #0000000d;}.mui-style-10aqcja-DataInsight-cardWrapper:hover .mui-style-28-DataInsight-button-ref{-webkit-background-size:100% 100%;background-size:100% 100%;}.mui-style-7sxby4-DataInsight-card{background-color:#fff;color:rgba(0', ' 0.103', ' 0.104', ' 0.87);-webkit-transition:box-shadow 300ms cubic-bezier(0.4.2', ' 0.105', ' 0.2.40', ' 1) 0ms;transition:box-shadow 300ms cubic-bezier(0.4.2', ' 0.106', ' 0.2.41', ' 1) 0ms;box-shadow:var(--Paper-shadow);background-image:var(--Paper-overlay);overflow:hidden;border-color:#ebebeb;box-shadow:0px 0px 0px #00000000;border-width:1px;border-style:solid;padding:24px;height:600px;max-width:100%;margin-bottom:12px;-webkit-transition:box-shadow 0.5s ease;transition:box-shadow 0.5s ease;width:100%;overflow:visible;}.mui-style-pn485x-ThemeStatistics-illustration{margin-bottom:16px;}.mui-style-xqliwt-ThemeStatistics-root{display:grid;grid-template-columns:repeat( auto-fit', ' minmax(250px', ' 1fr) );}@media (max-width:599.95px){.mui-style-xqliwt-ThemeStatistics-root{grid-template-columns:repeat(2', ' 1fr);}}.mui-style-4ex6rx{padding:1rem;cursor:pointer;-webkit-transition:background-color 150ms cubic-bezier(0.4', ' 0.107', ' 0.2.42', ' 1) 0ms;transition:background-color 150ms cubic-bezier(0.4.3', ' 0.108', ' 0.2.43', ' 1) 0ms;}.mui-style-4ex6rx:hover{background-color:#EBF3F9;}.mui-style-1cxnjrt{margin:0;font-weight:700;font-size:13px;line-height:18px;letter-spacing:0;font-family:Noto Sans', \"'-apple-system'.12\", \"'BlinkMacSystemFont'.12\", \"'Segoe UI'.12\", \"'Roboto'.12\", \"'Helvetica Neue'.12\", \"'Arial'.12\", \"'sans-serif'.12\", \"'Apple Color Emoji'.12\", \"'Segoe UI Emoji'.12\", \"'Segoe UI Symbol';margin-bottom:1rem;}.mui-style-o3djwr{margin:0;font-weight:400;font-size:14px;line-height:20px;letter-spacing:0;}.mui-style-7c8wqm{margin:0;font-weight:700;font-size:32px;line-height:64px;letter-spacing:0;font-family:Noto Sans\", \"'-apple-system'.13\", \"'BlinkMacSystemFont'.13\", \"'Segoe UI'.13\", \"'Roboto'.13\", \"'Helvetica Neue'.13\", \"'Arial'.13\", \"'sans-serif'.13\", \"'Apple Color Emoji'.13\", \"'Segoe UI Emoji'.13\", \"'Segoe UI Symbol';padding-top:80px;padding-left:24px;padding-right:24px;margin-bottom:32px;color:#23305f;}.mui-style-1ka0xgm-FeatureCarousel-texts{z-index:2;position:-webkit-sticky;position:sticky;top:5rem;row-gap:1rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-flex-basis:330px;-ms-flex-preferred-size:330px;flex-basis:330px;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;background:#fff;margin-left:24px;margin-bottom:100px;}@media (max-width:899.95px){.mui-style-1ka0xgm-FeatureCarousel-texts{-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin:0px 24px;-webkit-flex-basis:unset;-ms-flex-preferred-size:unset;flex-basis:unset;}}.mui-style-9whjg2-FeatureCarousel-images{-webkit-box-flex:5;-webkit-flex-grow:5;-ms-flex-positive:5;flex-grow:5;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;overflow-x:hidden;}.mui-style-16kaw1y-FeatureCarousel-featureImage{margin-bottom:1rem;-webkit-transition:opacity 0.5s ease\", 'filter 0.5s ease', '-webkit-transform 0.5s ease;transition:opacity 0.5s ease', 'filter 0.5s ease.1', 'transform 0.5s ease;-webkit-transform:scale(0.9);-moz-transform:scale(0.9);-ms-transform:scale(0.9);transform:scale(0.9);opacity:0.3;-webkit-filter:grayscale(0.5);filter:grayscale(0.5);}.mui-style-16kaw1y-FeatureCarousel-featureImage.mui-style-xxws-FeatureCarousel-active-ref{-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1);}.mui-style-t8xy5e-FeatureCarousel-featureItem-FeatureCarousel-inactive{padding:24px;-webkit-transition:opacity 0.5s ease;transition:opacity 0.5s ease;opacity:0.3;-webkit-filter:grayscale(1);filter:grayscale(1);}@media (max-width:899.95px){.mui-style-t8xy5e-FeatureCarousel-featureItem-FeatureCarousel-inactive{display:none;}}.mui-style-5nla4c-FeatureCarousel-container{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;gap:32px;}@media (max-width:899.95px){.mui-style-5nla4c-FeatureCarousel-container{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}}.mui-style-ebkpew{margin:0;font-weight:700;font-size:16px;line-height:24px;letter-spacing:0;font-family:Noto Sans', \"'-apple-system'.14\", \"'BlinkMacSystemFont'.14\", \"'Segoe UI'.14\", \"'Roboto'.14\", \"'Helvetica Neue'.14\", \"'Arial'.14\", \"'sans-serif'.14\", \"'Apple Color Emoji'.14\", \"'Segoe UI Emoji'.14\", \"'Segoe UI Symbol';color:#0069b4;}.mui-style-n69y0b{margin:0;font-weight:700;font-size:18px;line-height:24px;letter-spacing:0;font-family:Noto Sans\", \"'-apple-system'.15\", \"'BlinkMacSystemFont'.15\", \"'Segoe UI'.15\", \"'Roboto'.15\", \"'Helvetica Neue'.15\", \"'Arial'.15\", \"'sans-serif'.15\", \"'Apple Color Emoji'.15\", \"'Segoe UI Emoji'.15\", \"'Segoe UI Symbol';margin-bottom:8px;color:#23305f;}.mui-style-jd03v9{margin:0;font-weight:400;font-size:14px;line-height:20px;letter-spacing:0;color:#585858;}.mui-style-79elbk{position:relative;}.mui-style-1hz5k7v{height:100px;position:absolute;}.mui-style-b1gm9m-root{z-index:0;color:white;background:#0069b4;--uis-button-group-tab-color:white;--uis-button-group-tab-disabled-color:rgba(255\", ' 255.2', ' 255.3', ' 0.28);--uis-button-group-tabs-indicator-background:#479acf;--uis-button-group-tab-selected-color:white;--uis-button-group-tab-border-color:#479acf;--mui-divider-color:white;--mui-slider-mark-color:white;--mui-slider-rail-color:white;--mui-slider-track-color:white;--mui-slider-thumb-color:white;--mui-outlined-input-color:white;--mui-outlined-input-notched-outline-border-color:#479acf;--mui-outlined-input-hover-notched-outline-border-color:#003558;--mui-outlined-input-background-color:#479acf;--mui-autocomplete-popup-indicator-color:rgba(255', ' 255.4', ' 255.5', ' 0.8);--mui-autocomplete-clear-indicator-color:rgba(255', ' 255.6', ' 255.7', ' 0.8);--mui-autocomplete-tag-background-color:#0069b4;--mui-chip-filled-color:white;--mui-chip-filled-background-color:#0069b4;--mui-autocomplete-tag-color:white;--mui-button-outlined-primary-border-color:white;--mui-button-outlined-primary-color:white;--mui-button-outlined-primary-hover-background-color:#479acf;--mui-button-contained-primary-background-color:white;--mui-button-contained-primary-color:#0069b4;--mui-button-contained-primary-hover-background-color:#ebf3f9;--mui-button-text-primary-border-color:#0069b4;--mui-button-text-primary-color:#fff;--mui-button-text-primary-hover-background-color:transparent;--mui-select-icon-fill:white;--uis-radio-group-well-background:#479acf;--uis-radio-group-well-color:white;--uis-radio-group-well-color-selected:white;}.mui-style-t0051x{padding-left:24px;padding-right:24px;}.mui-style-18yqq8n{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:16px;padding-top:16px;padding-bottom:16px;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.mui-style-1ew9uej{margin:0;font-weight:700;font-size:18px;line-height:24px;letter-spacing:0;font-family:Noto Sans', \"'-apple-system'.16\", \"'BlinkMacSystemFont'.16\", \"'Segoe UI'.16\", \"'Roboto'.16\", \"'Helvetica Neue'.16\", \"'Arial'.16\", \"'sans-serif'.16\", \"'Apple Color Emoji'.16\", \"'Segoe UI Emoji'.16\", \"'Segoe UI Symbol';}.mui-style-1sh75vq{-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;}.mui-style-1ri9ct8{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;font-family:Noto Sans\", \"'-apple-system'.17\", \"'BlinkMacSystemFont'.17\", \"'Segoe UI'.17\", \"'Roboto'.17\", \"'Helvetica Neue'.17\", \"'Arial'.17\", \"'sans-serif'.17\", \"'Apple Color Emoji'.17\", \"'Segoe UI Emoji'.17\", \"'Segoe UI Symbol';font-weight:500;font-size:0.875rem;line-height:1.75;text-transform:uppercase;min-width:64px;padding:6px 16px;border:0;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4.3\", ' 0.109', ' 0.2.44', ' 1) 0ms.20', 'box-shadow 250ms cubic-bezier(0.4.6', ' 0.110', ' 0.2.45', ' 1) 0ms.21', 'border-color 250ms cubic-bezier(0.4.6', ' 0.111', ' 0.2.46', ' 1) 0ms.22', 'color 250ms cubic-bezier(0.4.6', ' 0.112', ' 0.2.47', ' 1) 0ms;transition:background-color 250ms cubic-bezier(0.4.3', ' 0.113', ' 0.2.48', ' 1) 0ms.23', 'box-shadow 250ms cubic-bezier(0.4.7', ' 0.114', ' 0.2.49', ' 1) 0ms.24', 'border-color 250ms cubic-bezier(0.4.7', ' 0.115', ' 0.2.50', ' 1) 0ms.25', 'color 250ms cubic-bezier(0.4.7', ' 0.116', ' 0.2.51', ' 1) 0ms;color:var(--variant-containedColor);background-color:var(--variant-containedBg);box-shadow:0px 1px 5px #00000014.1', '0px 1px 2px #0000000f;--variant-textColor:#0069b4;--variant-outlinedColor:#0069b4;--variant-outlinedBorder:rgba(0.1', ' 105.11', ' 180.11', ' 0.5);--variant-containedColor:#fff;--variant-containedBg:#0069b4;font-style:normal;font-weight:400;text-transform:none;line-height:24px;border-radius:0px;box-shadow:none;background-color:var(--mui-button-contained-primary-background-color);color:var(--mui-button-contained-primary-color);font-size:16px;min-height:48px;padding:0 24px;}.mui-style-1ri9ct8::-moz-focus-inner{border-style:none;}.mui-style-1ri9ct8.Mui-disabled{pointer-events:none;cursor:default;}@media print{.mui-style-1ri9ct8{-webkit-print-color-adjust:exact;color-adjust:exact;}}.mui-style-1ri9ct8:hover{-webkit-text-decoration:none;text-decoration:none;}.mui-style-1ri9ct8.Mui-disabled{color:rgba(0', ' 0.117', ' 0.118', ' 0.26);}.mui-style-1ri9ct8:hover{box-shadow:0px 5px 20px #00000014', '0px 2px 6px #0000000d;}@media (hover: none){.mui-style-1ri9ct8:hover{box-shadow:0px 1px 5px #00000014', '0px 1px 2px #0000000f;}}.mui-style-1ri9ct8:active{box-shadow:none;}.mui-style-1ri9ct8.Mui-focusVisible{box-shadow:0px 10px 20px #0000000d', '1px 10px 70px #00000021;}.mui-style-1ri9ct8.Mui-disabled{color:rgba(0', ' 0.119', ' 0.120', ' 0.26);box-shadow:0px 0px 0px #00000000;background-color:rgba(0.1', ' 0.121', ' 0.122', ' 0.12);}@media (hover: hover){.mui-style-1ri9ct8:hover{--variant-containedBg:#00497c;--variant-textBg:rgba(0', ' 105.12', ' 180.12', ' 0.04);--variant-outlinedBorder:#0069b4;--variant-outlinedBg:rgba(0.3', ' 105.13', ' 180.13', ' 0.04);}}.mui-style-1ri9ct8:hover{box-shadow:0px 1px 5px #00000014', '0px 1px 2px #0000000f;}.mui-style-1ri9ct8:hover{background-color:var(--mui-button-contained-primary-hover-background-color);}.mui-style-1npii3n{display:inherit;margin-right:-4px;margin-left:8px;}.mui-style-1npii3n>*:nth-of-type(1){font-size:20px;}.mui-style-9wy2gx-DataInsightCarousel-content{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;gap:40px;padding:40px 0px;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;margin:0 auto;}.mui-style-1d6k93d-DataInsightCarousel-root{background-color:#23305f;min-height:80px;z-index:3;padding:0px 24px;}.mui-style-13yzri3{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:2.25rem;color:white;margin-bottom:2.5rem;}.mui-style-13yzri3 a{color:white;}.mui-style-1s5a2t9{margin:0;font:inherit;line-height:inherit;letter-spacing:inherit;color:#0069b4;-webkit-text-decoration:underline;text-decoration:underline;text-decoration-color:var(--Link-underlineColor);--Link-underlineColor:rgba(0', ' 105.14', ' 180.14', ' 0.4);}.mui-style-1s5a2t9:hover{text-decoration-color:inherit;}.mui-style-16hnoe6{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:1rem;}.mui-style-1wbsfxw{margin:0;font:inherit;line-height:inherit;letter-spacing:inherit;color:#0069b4;-webkit-text-decoration:none;text-decoration:none;font-weight:400;font-size:14px;line-height:20px;letter-spacing:0;color:#fff;}.mui-style-1wbsfxw:hover{-webkit-text-decoration:underline;text-decoration:underline;}</style><link rel=\"preload\" href=\"/_next/static/css/1033070d5749b2be.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/1033070d5749b2be.css\" data-n-g=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-42372ed130431b0a.js\"></script><script src=\"/_next/static/chunks/webpack-bca2e06970a261fa.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-9756650c55492109.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-ebe840b189d241c9.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-98f7829ed5316c05.js\" defer=\"\"></script><script src=\"/_next/static/chunks/374-ba8c5dcff741133a.js\" defer=\"\"></script><script src=\"/_next/static/chunks/673-ac48017742f18459.js\" defer=\"\"></script><script src=\"/_next/static/chunks/112-42136a4a536b2107.js\" defer=\"\"></script><script src=\"/_next/static/chunks/947-9f051b6d1b6d449c.js\" defer=\"\"></script><script src=\"/_next/static/chunks/900-7136369a691e7282.js\" defer=\"\"></script><script src=\"/_next/static/chunks/862-04dbcfd044d8ee8b.js\" defer=\"\"></script><script src=\"/_next/static/chunks/596-76167896fd02a9b5.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/index-88e9f6dde426fe77.js\" defer=\"\"></script><script src=\"/_next/static/5ISdDpIt4JRqAJXRjlVvz/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/5ISdDpIt4JRqAJXRjlVvz/_ssgManifest.js\" defer=\"\"></script><meta name=\"sentry-trace\" content=\"faec3555d25fcf66b893e52049090a47-cbc8f2ed9bfc6bab-0\"/><meta name=\"baggage\" content=\"sentry-environment=vercel-production', 'sentry-release=7aa3e59fafc14f8bef1c99de37e61ac2cbb58402', 'sentry-public_key=54b726bb4bf73ff58dbf2768716a3a82', 'sentry-trace_id=faec3555d25fcf66b893e52049090a47', 'sentry-sampled=false\"/></head><link rel=\"preconnect\" href=\"https://fonts.googleapis.com\"/><link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin=\"anonymous\"/><link crossorigin=\"anonymous\" href=\"https://fonts.googleapis.com/css2?family=Noto+Sans:wght@400;500;700&amp;display=swap\" rel=\"stylesheet\"/><body><div id=\"__next\"><button class=\"MuiButtonBase-root MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeSmall MuiButton-containedSizeSmall MuiButton-colorPrimary MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeSmall MuiButton-containedSizeSmall MuiButton-colorPrimary mui-style-gfhv8f-tinyButton-position\" tabindex=\"0\" type=\"button\" style=\"transition:opacity 0.5s ease;opacity:1\"><div class=\"MuiTypography-root MuiTypography-metaBold mui-style-167egg6\">Feedback?</div></button><div class=\"MuiBox-root mui-style-qm2s28-TopBar-container\"><header class=\"MuiPaper-root MuiPaper-elevation MuiPaper-elevation4 MuiAppBar-root MuiAppBar-colorPrimary MuiAppBar-positionFixed mui-fixed mui-style-5dfstq-TopBar-bar\" data-testid=\"navigation\" style=\"--Paper-shadow:0px 5px 20px #00000014', ' 0px 2px 6px #0000000d\"><div class=\"MuiBox-root mui-style-ygfnsq-TopBar-navFont\"><div class=\"MuiBox-root mui-style-1w24irv\"><a href=\"/\"><img alt=\"Logo Unesco\" loading=\"lazy\" width=\"170\" height=\"38\" decoding=\"async\" data-nimg=\"1\" style=\"color:transparent\" srcSet=\"/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-unesco.ed8acc9a.png&amp;w=256&amp;q=75 1x', ' /_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-unesco.ed8acc9a.png&amp;w=384&amp;q=75 2x\" src=\"/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-unesco.ed8acc9a.png&amp;w=384&amp;q=75\"/></a></div><div class=\"MuiStack-root mui-style-149sczi\"><nav class=\"MuiStack-root mui-style-1egeflc-TopBar-navFont-TopBar-desktopNav\"><span><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineNone mui-style-1wd0t83-topbarVariant\" href=\"/\">Home</a></span><div class=\"MuiBox-root mui-style-70qvj9\"><span><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineNone mui-style-1wd0t83-topbarVariant\" href=\"/browser\">Browse data</a></span></div><span><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineNone mui-style-1wd0t83-topbarVariant\" href=\"/resources\">Resources</a></span><span><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineNone mui-style-1wd0t83-topbarVariant\" href=\"/about\">About</a></span></nav><button class=\"MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeMedium mui-style-ed2cz-TopBar-menuBtn\" tabindex=\"0\" type=\"button\"><svg class=\"MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-style-q7mezt\" focusable=\"false\" aria-hidden=\"true\" viewBox=\"0 0 24 24\" data-testid=\"MenuIcon\"><path d=\"M3 18h18v-2H3zm0-5h18v-2H3zm0-7v2h18V6z\"></path></svg></button><div class=\"MuiBox-root mui-style-70qvj9\"><div class=\"MuiDivider-root MuiDivider-fullWidth MuiDivider-vertical mui-style-xt5v3l\" role=\"separator\" aria-orientation=\"vertical\"></div><section class=\"MuiBox-root mui-style-k341i1\" aria-label=\"Indicator cart\"><button class=\"MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeMedium mui-style-f024n4-cartTrigger\" tabindex=\"0\" type=\"button\" aria-label=\"cart\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"none\" viewBox=\"0 0 16 16\"><path fill=\"currentColor\" d=\"M15 3H8.4L5.7.3C5.5.1 5.3 0 5 0H1C.4 0 0 .4 0 1v14c0 .6.4 1 1 1h14c.6 0 1-.4 1-1V4c0-.6-.4-1-1-1\"></path><path fill=\"#fff\" fill-rule=\"evenodd\" d=\"m7.006 9.903 3.691-3.792.803.825-4.494 4.617L4.5 8.978l.803-.825z\" clip-rule=\"evenodd\"></path></svg></button></section><span><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineNone mui-style-1wd0t83-topbarVariant\" href=\"/view\">View data</a></span></div></div></div></header></div><div class=\"MuiBox-root mui-style-d6ketg\"><main class=\"MuiBox-root mui-style-0\"><div class=\"MuiBox-root mui-style-8c556v-hero\"><div class=\"MuiBox-root mui-style-ij0u24\"><div class=\"MuiBox-root mui-style-vrbv4l\"><div class=\"MuiBox-root mui-style-w9wc3r\"><div><h1 class=\"MuiTypography-root MuiTypography-display1 mui-style-1fq0z56\">Welcome to the UIS Data Browser</h1><div class=\"mui-style-1k5uq04-heroContent\"><div class=\"MuiStack-root mui-style-6r2fzw\"><p class=\"MuiTypography-root MuiTypography-body1 mui-style-1t98mfd\">The data browser allows users to <strong>view</strong> and <strong>filter data</strong> and <strong>metadata</strong>', ' <strong>visualize</strong> and <strong>share</strong> it or <strong>download</strong> it in various formats (csv', ' excel). </p><a class=\"MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-sizeMedium MuiButton-textSizeMedium MuiButton-colorPrimary MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-sizeMedium MuiButton-textSizeMedium MuiButton-colorPrimary mui-style-gu0jcc-cta\" tabindex=\"0\" href=\"/browser\">Browse Data</a></div></div></div><div class=\"MuiBox-root mui-style-1lv5skk\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"406\" height=\"405\" fill=\"none\" class=\"mui-style-1japxzf-symbol\" style=\"flex-shrink:0;margin-top:-100px;margin-bottom:-100px\"><g clip-path=\"url(#hero-uis-logo_svg__a)\"><path fill=\"#fff\" d=\"M154.79 188.805c-6.584 0-12.104 4.511-13.673 10.609H28.323c-1.569-6.098-7.088-10.609-13.673-10.609-7.808 0-14.13 6.323-14.13 14.13 0 7.808 6.322 14.131 14.13 14.131 6.585 0 12.104-4.511 13.673-10.61h112.803c1.569 6.099 7.089 10.61 13.673 10.61 7.808 0 14.131-6.323 14.131-14.131 0-7.807-6.323-14.13-14.131-14.13z\" opacity=\"0.5\"></path><path fill=\"#fff\" d=\"M235.994 139.418h7.051v17.306c0 3.418 1.691 5.398 5.025 5.398 3.334 0 5.109-1.98 5.109-5.398v-17.306h7.051v17.269c0 7.994-5.603 11.954-12.281 11.954-6.678 0-11.955-3.96-11.955-11.954zM265.164 139.418h7.051v28.925h-7.051zM287.801 168.645c-6.22 0-11.086-3.092-11.291-8.948h7.499c.206 2.223 1.607 3.297 3.587 3.297 1.98 0 3.381-1.027 3.381-2.718 0-5.361-14.467-2.475-14.383-12.729 0-5.483 4.492-8.527 10.554-8.527 6.061 0 10.553 3.128 10.833 8.648h-7.621c-.121-1.849-1.438-2.961-3.334-3.007-1.69-.038-2.97.821-2.97 2.633 0 5.025 14.299 2.765 14.299 12.441 0 4.866-3.792 8.9-10.554 8.9zM262.118 203.364c0 8.574-5.93 14.467-15.167 14.467h-10.834v-28.925h10.834c9.228 0 15.167 5.847 15.167 14.467zm-15.615 8.359c5.314 0 8.452-3.045 8.452-8.368 0-5.324-3.129-8.453-8.452-8.453h-3.334v16.811h3.334zM274.801 194.502c3.419 0 5.856 1.569 7.089 3.586v-3.26h7.051v22.994h-7.051v-3.259c-1.279 2.017-3.708 3.586-7.126 3.586-5.604 0-10.096-4.613-10.096-11.87 0-7.257 4.492-11.787 10.133-11.787zm2.064 6.136c-2.633 0-5.024 1.98-5.024 5.641s2.391 5.725 5.024 5.725c2.634 0 5.025-2.018 5.025-5.688s-2.344-5.688-5.025-5.688zM295.181 200.659h-2.802v-5.856h2.802v-5.604h7.051v5.604h4.614v5.856h-4.614v9.227c0 1.364.579 1.934 2.139 1.934h2.512v5.977h-3.586c-4.782 0-8.116-2.017-8.116-7.995zM319.52 194.502c3.418 0 5.856 1.569 7.089 3.586v-3.26h7.051v22.994h-7.051v-3.259c-1.28 2.017-3.708 3.586-7.126 3.586-5.604 0-10.096-4.613-10.096-11.87 0-7.257 4.492-11.787 10.133-11.787zm2.064 6.136c-2.634 0-5.025 1.98-5.025 5.641s2.391 5.725 5.025 5.725c2.634 0 5.025-2.018 5.025-5.688s-2.344-5.688-5.025-5.688zM249.594 267.268h-13.477v-28.924h13.02c5.893 0 9.395 2.923 9.395 7.499 0 3.503-2.101 5.772-4.903 6.594 3.381.701 5.566 3.671 5.566 6.967 0 4.782-3.502 7.874-9.601 7.874zm-1.812-23.283h-4.613v6.061h4.613c2.307 0 3.587-1.027 3.587-3.007 0-1.98-1.28-3.054-3.587-3.054m.495 11.207h-5.108v6.389h5.192c2.345 0 3.708-1.075 3.708-3.129 0-2.055-1.438-3.25-3.792-3.25zM270.337 267.273h-7.052V244.28h7.052v3.829c1.606-2.429 4.118-4.082 7.21-4.082v7.463h-1.934c-3.343 0-5.276 1.158-5.276 5.108zM291.371 267.577c-6.762 0-11.871-4.529-11.871-11.823 0-7.295 5.23-11.824 11.955-11.824 6.724 0 11.954 4.529 11.954 11.824 0 7.294-5.277 11.823-12.029 11.823zm0-6.098c2.512 0 4.865-1.85 4.865-5.725 0-3.876-2.306-5.726-4.781-5.726-2.475 0-4.782 1.812-4.782 5.726 0 3.913 2.139 5.725 4.698 5.725M304.764 244.277h7.051l3.25 16.447 3.876-16.447h7.462l3.914 16.363 3.212-16.363h6.632l-6.221 22.994h-7.789l-3.623-14.915-3.746 14.915h-7.742l-6.267-22.994zM352.21 267.577c-6.136 0-10.264-3.418-10.591-7.873h6.967c.169 1.607 1.607 2.681 3.54 2.681 1.812 0 2.765-.822 2.765-1.85 0-3.707-12.525-1.027-12.525-9.479 0-3.914 3.344-7.126 9.359-7.126 6.014 0 9.227 3.297 9.685 7.826h-6.51c-.205-1.559-1.401-2.596-3.381-2.596-1.644 0-2.559.663-2.559 1.774 0 3.671 12.45 1.074 12.571 9.648 0 3.997-3.54 7.005-9.311 7.005zM376.079 267.577c-6.761 0-11.618-4.529-11.618-11.823 0-7.295 4.782-11.824 11.618-11.824 6.837 0 11.46 4.455 11.46 11.459 0 .654-.037 1.364-.121 2.064h-15.952c.252 3.008 2.101 4.409 4.37 4.409 1.98 0 3.092-.99 3.671-2.223h7.5c-1.112 4.492-5.193 7.948-10.918 7.948zm-4.576-14.046h8.816c0-2.513-1.98-3.96-4.324-3.96s-4.081 1.401-4.492 3.96M398.282 267.273h-7.052V244.28h7.052v3.829c1.606-2.429 4.119-4.082 7.21-4.082v7.463h-1.933c-3.344 0-5.277 1.158-5.277 5.108zM102.854 219.896c9.378 0 16.98-7.602 16.98-16.979 0-9.378-7.602-16.979-16.98-16.979-9.377 0-16.979 7.601-16.979 16.979 0 9.377 7.602 16.979 16.979 16.979M14.625 217.066c7.804 0 14.13-6.326 14.13-14.131 0-7.804-6.326-14.13-14.13-14.13-7.804 0-14.13 6.326-14.13 14.13 0 7.805 6.326 14.131 14.13 14.131M154.783 217.066c7.804 0 14.131-6.326 14.131-14.131 0-7.804-6.327-14.13-14.131-14.13s-14.131 6.326-14.131 14.13c0 7.805 6.327 14.131 14.131 14.131\"></path><path fill=\"#fff\" d=\"M102.714 257.44c-30.316 0-54.982-24.665-54.982-54.982 0-30.316 24.666-54.981 54.982-54.981 11.17 0 21.92 3.334 31.092 9.629a4.696 4.696 0 0 1-5.315 7.742c-7.593-5.221-16.512-7.976-25.767-7.976-25.133 0-45.587 20.454-45.587 45.586 0 25.133 20.454 45.587 45.587 45.587a45.42 45.42 0 0 0 24.432-7.098 4.698 4.698 0 0 1 6.482 1.438 4.698 4.698 0 0 1-1.439 6.482 54.806 54.806 0 0 1-29.475 8.564z\" opacity=\"0.5\"></path><path fill=\"#fff\" d=\"M102.714 257.432c-30.316 0-54.982-24.665-54.982-54.981 0-18.119 8.929-35.07 23.891-45.353a4.695 4.695 0 1 1 5.314 7.742 45.627 45.627 0 0 0-19.809 37.611c0 25.132 20.454 45.586 45.586 45.586a45.449 45.449 0 0 0 24.601-7.201 4.695 4.695 0 0 1 6.491 1.41 4.703 4.703 0 0 1-1.411 6.491 54.801 54.801 0 0 1-29.681 8.695\"></path><path fill=\"#fff\" d=\"M185.969 207.107a4.695 4.695 0 0 1-4.697-4.698c0-43.345-35.266-78.611-78.611-78.611a4.695 4.695 0 0 1-4.698-4.698 4.696 4.696 0 0 1 4.698-4.698c48.528 0 88.006 39.479 88.006 88.007a4.696 4.696 0 0 1-4.698 4.698\" opacity=\"0.5\"></path><path fill=\"#fff\" d=\"M185.948 207.1a4.695 4.695 0 0 1-4.698-4.698c0 43.345-35.266 78.611-78.611 78.611-27.636 0-53.572-14.784-67.674-38.591a4.7 4.7 0 0 0-6.435-1.643 4.692 4.692 0 0 0-1.644 6.434c15.793 26.646 44.82 43.196 75.762 43.196 48.529 0 88.007-39.478 88.007-88.007a4.696 4.696 0 0 1-4.698 4.698z\"></path></g><defs><clipPath id=\"hero-uis-logo_svg__a\"><path fill=\"#fff\" d=\"M.494 114.402h405v176.004h-405z\"></path></clipPath></defs></svg></div></div></div></div><div class=\"MuiBox-root mui-style-l0wajo-root\"><div class=\"mui-style-g6ot07-smallerLine\"></div><svg width=\"155\" height=\"80\" viewBox=\"0 0 155 80\" fill=\"#2684c2\" class=\"mui-style-867tzq-wave\" aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M45.1767 80C35.5028 80 26.7918 74.6188 22.4419 66.8969L0 22V0H48H155V80H45.1767Z\"></path></svg><div class=\"mui-style-15p1w1i-logoContainer\"><img src=\"/logo-unesco-uis-extended.png\" width=\"61.6\" height=\"45\" alt=\"Logo UIS Extended\"/></div></div></div><div class=\"MuiBox-root mui-style-11z7gjw-contentPageSections\"><div class=\"MuiBox-root mui-style-vrbv4l\"><h1 class=\"MuiTypography-root MuiTypography-h1 mui-style-wzh0ll\">Key facts</h1><div class=\"mui-style-t4aypk-Keyfact-masonry\" style=\"--cols:3\"><div class=\"MuiPaper-root MuiPaper-elevation MuiPaper-elevation1 MuiCard-root mui-style-hazch5-Keyfact-card-keyfact-Keyfact-tall\" style=\"--Paper-shadow:0px 1px 2px #0000000d\"><div class=\"MuiStack-root mui-style-8naohf\"><a class=\"MuiChip-root MuiChip-filled MuiChip-sizeSmall MuiChip-colorDefault MuiChip-filledDefault mui-style-173mjkp-Keyfact-targetChip\" href=\"https://databrowser.uis.unesco.org/browser/EDUCATION/UIS-SDG4Monitoring/t4.1/i4.1.1\"><span class=\"MuiChip-label MuiChip-labelSmall mui-style-4y436t\">4.1.1<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"16\" fill=\"none\" viewBox=\"0 0 16 16\" class=\"mui-style-1a30ymk-Keyfact-targetIcon\"><path fill=\"currentColor\" fill-rule=\"evenodd\" d=\"M5 13.067 6.445 14.5 13 8 6.445 1.5 5 2.933 10.109 8z\" clip-rule=\"evenodd\"></path></svg></span></a></div><p class=\"MuiTypography-root MuiTypography-h1 mui-style-22-Keyfact-title-ref mui-style-1flbsx1-Keyfact-title\">Only 44% of students</p><p class=\"MuiTypography-root MuiTypography-h4 mui-style-22-Keyfact-subtitle-ref mui-style-m9650t-Keyfact-subtitle\">attain minimum proficiency in mathematics by the end of primary school. </p><hr class=\"MuiDivider-root MuiDivider-fullWidth mui-style-1ukbohm\"/><div class=\"MuiTypography-root MuiTypography-meta mui-style-1te1yf2-Keyfact-body\"><p>Being in school does not guarantee that a child receives high-quality education. In fact', ' in many countries', ' the data shows that children learn very little. Globally', ' four in ten students do not meet minimum proficiency levels in reading by the end of primary (SDG 4 Benchmark Indicator 4.1.1). Even fewer achieve basic skills in mathematics', ' with less than half (44%) meeting minimum proficiency levels at the end of primary.</p>']\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | ⏱️  Start: Orchestrator.full_cleaning\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | 🧹 Start cleaning (6 sources)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 STEP 2/4: INITIAL VALIDATION\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "🧹 STEP 3/4: DATA CLEANING\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning:   0%|                                                           | 0/6 [00:00<?, ?source/s]2025-10-17 22:58:06 | INFO     | __main__ | ⏱️  Start: DataCleaner.clean_dataset\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🧹 Cleaning: world_bank\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ 7 columns standardized\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🔍 10 outliers handled\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ Cleaning done: 80 → 80 rows (0 removed)\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | ✅ Done: DataCleaner.clean_dataset in 0.021s\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🌍 World Bank specific cleaning\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | 💾 Saved: world_bank_cleaned.csv\n",
      "Cleaning:   0%|                                                           | 0/6 [00:00<?, ?source/s]2025-10-17 22:58:06 | INFO     | __main__ | ⏱️  Start: DataCleaner.clean_dataset\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🧹 Cleaning: web_scraping\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ 14 columns standardized\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🗑️ 1 duplicates removed\n",
      "2025-10-17 22:58:06 | WARNING  | DataCleaner | ⚠️ 7 columns dropped\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🔍 49 outliers handled\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ Cleaning done: 149 → 148 rows (1 removed)\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | ✅ Done: DataCleaner.clean_dataset in 0.027s\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | 💾 Saved: web_scraping_cleaned.csv\n",
      "Cleaning:   0%|                                                           | 0/6 [00:00<?, ?source/s]2025-10-17 22:58:06 | INFO     | __main__ | ⏱️  Start: DataCleaner.clean_dataset\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🧹 Cleaning: geographic_cities\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ 8 columns standardized\n",
      "2025-10-17 22:58:06 | WARNING  | DataCleaner | ⚠️ 1 columns dropped\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🔍 10 outliers handled\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ Cleaning done: 3480 → 3480 rows (0 removed)\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | ✅ Done: DataCleaner.clean_dataset in 0.145s\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🗺️ Geographic specific cleaning\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | 💾 Saved: geographic_cities_cleaned.csv\n",
      "Cleaning:  50%|█████████████████████████▌                         | 3/6 [00:00<00:00, 13.59source/s]2025-10-17 22:58:06 | INFO     | __main__ | ⏱️  Start: DataCleaner.clean_dataset\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🧹 Cleaning: geographic_admin_pays\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ 8 columns standardized\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🔄 1 type conversions\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ Cleaning done: 1 → 1 rows (0 removed)\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | ✅ Done: DataCleaner.clean_dataset in 0.011s\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🗺️ Geographic specific cleaning\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | 💾 Saved: geographic_admin_pays_cleaned.csv\n",
      "Cleaning:  50%|█████████████████████████▌                         | 3/6 [00:00<00:00, 13.59source/s]2025-10-17 22:58:06 | INFO     | __main__ | ⏱️  Start: DataCleaner.clean_dataset\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🧹 Cleaning: geographic\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ 10 columns standardized\n",
      "2025-10-17 22:58:06 | WARNING  | DataCleaner | ⚠️ 3 columns dropped\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "/tmp/ipykernel_51242/9868087.py:90: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_vals = pd.to_datetime(df[col], errors=\"coerce\")\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🔍 10 outliers handled\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ Cleaning done: 3481 → 3481 rows (0 removed)\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | ✅ Done: DataCleaner.clean_dataset in 0.140s\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🗺️ Geographic specific cleaning\n",
      "2025-10-17 22:58:06 | INFO     | __main__ | 💾 Saved: geographic_cleaned.csv\n",
      "Cleaning:  83%|██████████████████████████████████████████▌        | 5/6 [00:00<00:00, 12.21source/s]2025-10-17 22:58:06 | INFO     | __main__ | ⏱️  Start: DataCleaner.clean_dataset\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | 🧹 Cleaning: external\n",
      "2025-10-17 22:58:06 | INFO     | DataCleaner | ✅ 585 columns standardized\n",
      "2025-10-17 22:58:07 | ERROR    | __main__ | ❌ Failed: DataCleaner.clean_dataset after 0.152s - 'DataFrame' object has no attribute 'str'\n",
      "2025-10-17 22:58:07 | ERROR    | __main__ | ❌ Cleaning error external: 'DataFrame' object has no attribute 'str'\n",
      "Cleaning: 100%|███████████████████████████████████████████████████| 6/6 [00:00<00:00, 10.79source/s]\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | ✅ Cleaning done: 5 sources processed\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | ✅ Done: Orchestrator.full_cleaning in 0.562s\n",
      "2025-10-17 22:58:07 | INFO     | DataCleaner | 📊 Cleaning summary generated\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | 📖 Creating data dictionary\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | 💾 Dictionary saved: docs/data_dictionary.csv\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | 🔗 Consolidating final datasets\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | 💾 Saved: economic_indicators.csv\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | 💾 Saved: geographic_cities.csv\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | 💾 Saved: geographic_admin_pays.csv\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | 💾 Saved: geographic.csv\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | 💾 Saved: web_scraping.csv\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | ✅ 5 final datasets created\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | 🔍 Data quality validation\n",
      "2025-10-17 22:58:07 | WARNING  | __main__ | ⚠️ Issues detected in 1 sources\n",
      "2025-10-17 22:58:07 | WARNING  | __main__ |   - web_scraping: Duplicates: 8\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | ✅ Done: Orchestrator.complete_pipeline in 148.094s\n",
      "2025-10-17 22:58:07 | INFO     | __main__ | ✅ Done: Main.execution in 148.117s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 STEP 4/4: GENERATING DELIVERABLES\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "📊 COLLECTION SUMMARY\n",
      "====================================================================================================\n",
      "               source  records  columns  memory_mb  has_nulls  null_pct  numeric_cols  date_cols  duplicates       date\n",
      "           world_bank       59        7       0.02      False      0.00             2          0           0 2025-10-17\n",
      "         web_scraping      148        7       0.05       True      7.63             2          1           8 2025-10-17\n",
      "    geographic_cities     3172        7       0.83      False      0.00             3          0           0 2025-10-17\n",
      "geographic_admin_pays        1        8       0.00      False      0.00             4          0           0 2025-10-17\n",
      "           geographic     3173        7       0.83       True      0.00             3          0           0 2025-10-17\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "🔗 STEP 5/5: CONSOLIDATION & EXPORT\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "💾 Cleaning summary: data_task_1/processed/cleaning_summary.csv\n",
      "\n",
      "               source  initial_rows  final_rows  rows_removed  removal_percentage  duplicates_removed  nulls_handled  outliers_removed  columns_standardized  columns_dropped  types_converted  issues_count           timestamp\n",
      "           world_bank            80          80             0                0.00                   0              0                10                     7                0                0             0 2025-10-17 22:58:06\n",
      "         web_scraping           149         148             1                0.67                   1              0                49                    14                7                0             7 2025-10-17 22:58:06\n",
      "    geographic_cities          3480        3480             0                0.00                   0              0                10                     8                1                0             1 2025-10-17 22:58:06\n",
      "geographic_admin_pays             1           1             0                0.00                   0              0                 0                     8                0                1             0 2025-10-17 22:58:06\n",
      "           geographic          3481        3481             0                0.00                   0              0                10                    10                3                0             3 2025-10-17 22:58:06\n",
      "\n",
      "======================================================================\n",
      "RÉSUMÉ DES PERFORMANCES\n",
      "======================================================================\n",
      "  Total Operations: 48\n",
      "  Successful: 47\n",
      "  Failed: 1\n",
      "  Total Duration: 418.627\n",
      "  Avg Duration: 8.721\n",
      "  Total Items: 80\n",
      "======================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "✅ PIPELINE COMPLETED\n",
      "====================================================================================================\n",
      "📂 Raw data: data_task_1/raw\n",
      "📂 Cleaned data: data_task_1/processed\n",
      "📂 Final data: data_task_1/final_data\n",
      "📂 Documentation: docs\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "📋 FINAL RESULTS:\n",
      "  - Sources collected: 6\n",
      "  - Sources cleaned: 5\n",
      "  - Final datasets: 5\n",
      "  - Variables documented: 36\n",
      "  ⚠️ Remaining issues: 1 sources\n",
      "\n",
      "⏱️ GLOBAL PERFORMANCE:\n",
      "  - Total operations: 48\n",
      "  - Successful: 47\n",
      "  - Failed: 1\n",
      "  - Total duration: 418.627s\n",
      "  - Average duration: 8.721s\n",
      "  - Items processed: 80\n",
      "\n",
      "💾 Performance metrics: logs/performance_metrics.csv\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
